{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIBrRDzLpcQO"
      },
      "outputs": [],
      "source": [
        "# 시계열 데이터 - "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "시계열 데이터 \n",
        "\n",
        "1.시간정보가 들어있는 데이터\n",
        "*   \"세상에는 시계열 데이터가 참 많다\n",
        "*   단어가 나타내는 순서가 중요하다\n",
        "*   샘플의 길이가 다름    \n",
        "2.시계열 데이터를 인식하는 고전적인 모델\n",
        "*   ARIMA, SARIMA\n",
        "*   Prophet 등...\n",
        "3.시계열 데이터를 인식하는 딥러닝 모델\n",
        "*   순환 신경망(RNN)\n",
        "*   LSTM(Long short term memory) : 선별기억능력을 갖춰 장기 문맥처리에 유리\n"
      ],
      "metadata": {
        "id": "epzGAJuypkTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "매일 기온,  습도, 미세먼지 농도를 기록한다.  a1 = (23.2,42,0.25) a2=(, , ,)\n",
        "* x = (a1,a2,a3 ,,,, at)\n",
        "* 대표적인 응용은 미래 예측(prediction 또는 forecasting)\n",
        "1.   내일 주가예측\n",
        "2.   내일 날씨 예측\n",
        "3.   기계의 고장 예측\n",
        "4.   풍속과 풍향 예측(풍력 발전기의 효율 향상)\n",
        "5.   농산물 가격/수요량 예측\n",
        "6.   언어번역에 응용\n",
        "7.   생성모델에 응용(사진을 보고 설명 문장 생성)\n"
      ],
      "metadata": {
        "id": "JVDTHUXirYBJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "비트코인 예측하기"
      ],
      "metadata": {
        "id": "Ee_OW-JktH86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "MJ40R2s8tJfK"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('bitcoin.csv','r')\n",
        "df = pd.read_csv(f,header=0)\n"
      ],
      "metadata": {
        "id": "UvKHa4o2tbYJ"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Closing Price (USD) 종가만 가져온다"
      ],
      "metadata": {
        "id": "4pEExwQfuzBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq = df[['Closing Price (USD)']].to_numpy()"
      ],
      "metadata": {
        "id": "oipLVQwtu1Sy"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seq2dataset(seq,window,horizon):\n",
        "    X=[]; Y=[]\n",
        "    for i in range(len(seq)-(window+horizon)+1):\n",
        "        x=seq[i:(i+window)]\n",
        "        y=(seq[i+window+horizon-1])\n",
        "        X.append(x); Y.append(y)\n",
        "    return np.array(X), np.array(Y)"
      ],
      "metadata": {
        "id": "TeAXBJ0OvIBx"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w=7 # 윈도우 크기\n",
        "h=1 # 수평선 계수\n",
        "\n",
        "X,Y = seq2dataset(seq,w,h)"
      ],
      "metadata": {
        "id": "TTAu1oU-vL5R"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 집합과 테스트 집합으로 분할\n",
        "split=int(len(X)*0.7)\n",
        "x_train=X[0:split]; y_train=Y[0:split]\n",
        "x_test=X[split:]; y_test=Y[split:]"
      ],
      "metadata": {
        "id": "jqXLcxo28zlx"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj6jm9aG9W-K",
        "outputId": "69f15d96-a00b-4576-c716-b0e3920ac75f"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM 모델 설계와 학습\n",
        "model=Sequential()\n",
        "model.add(LSTM(units=128,activation='relu',input_shape=x_train[0].shape))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mae',optimizer='adam',metrics=['mae'])\n",
        "hist=model.fit(x_train,y_train,epochs=200,batch_size=1,validation_data=(x_test,y_test),verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEyifYza82YZ",
        "outputId": "618da7da-ca56-42ae-fe8c-3cae006ce156"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "250/250 - 2s - loss: 1685.9900 - mae: 1685.9900 - val_loss: 474.6467 - val_mae: 474.6467 - 2s/epoch - 10ms/step\n",
            "Epoch 2/200\n",
            "250/250 - 1s - loss: 550.0173 - mae: 550.0173 - val_loss: 337.6149 - val_mae: 337.6149 - 996ms/epoch - 4ms/step\n",
            "Epoch 3/200\n",
            "250/250 - 1s - loss: 529.8935 - mae: 529.8935 - val_loss: 493.8566 - val_mae: 493.8566 - 977ms/epoch - 4ms/step\n",
            "Epoch 4/200\n",
            "250/250 - 1s - loss: 524.9998 - mae: 524.9998 - val_loss: 322.3449 - val_mae: 322.3449 - 929ms/epoch - 4ms/step\n",
            "Epoch 5/200\n",
            "250/250 - 1s - loss: 516.8251 - mae: 516.8251 - val_loss: 566.7067 - val_mae: 566.7067 - 1s/epoch - 4ms/step\n",
            "Epoch 6/200\n",
            "250/250 - 1s - loss: 528.4459 - mae: 528.4459 - val_loss: 511.4722 - val_mae: 511.4722 - 1s/epoch - 4ms/step\n",
            "Epoch 7/200\n",
            "250/250 - 1s - loss: 561.3167 - mae: 561.3167 - val_loss: 305.9604 - val_mae: 305.9604 - 927ms/epoch - 4ms/step\n",
            "Epoch 8/200\n",
            "250/250 - 1s - loss: 491.8047 - mae: 491.8047 - val_loss: 311.7328 - val_mae: 311.7328 - 934ms/epoch - 4ms/step\n",
            "Epoch 9/200\n",
            "250/250 - 1s - loss: 458.5429 - mae: 458.5429 - val_loss: 425.4603 - val_mae: 425.4603 - 1s/epoch - 4ms/step\n",
            "Epoch 10/200\n",
            "250/250 - 1s - loss: 485.2191 - mae: 485.2191 - val_loss: 289.8835 - val_mae: 289.8835 - 961ms/epoch - 4ms/step\n",
            "Epoch 11/200\n",
            "250/250 - 1s - loss: 529.4968 - mae: 529.4968 - val_loss: 366.8778 - val_mae: 366.8778 - 1s/epoch - 4ms/step\n",
            "Epoch 12/200\n",
            "250/250 - 1s - loss: 486.8869 - mae: 486.8869 - val_loss: 610.8090 - val_mae: 610.8090 - 1s/epoch - 4ms/step\n",
            "Epoch 13/200\n",
            "250/250 - 1s - loss: 438.1591 - mae: 438.1591 - val_loss: 697.6478 - val_mae: 697.6478 - 1s/epoch - 4ms/step\n",
            "Epoch 14/200\n",
            "250/250 - 1s - loss: 868.2014 - mae: 868.2014 - val_loss: 1999.4678 - val_mae: 1999.4678 - 925ms/epoch - 4ms/step\n",
            "Epoch 15/200\n",
            "250/250 - 1s - loss: 609.7247 - mae: 609.7247 - val_loss: 321.0951 - val_mae: 321.0951 - 1s/epoch - 4ms/step\n",
            "Epoch 16/200\n",
            "250/250 - 1s - loss: 566.6058 - mae: 566.6058 - val_loss: 319.8151 - val_mae: 319.8151 - 1s/epoch - 4ms/step\n",
            "Epoch 17/200\n",
            "250/250 - 1s - loss: 518.2106 - mae: 518.2106 - val_loss: 345.3527 - val_mae: 345.3527 - 1s/epoch - 4ms/step\n",
            "Epoch 18/200\n",
            "250/250 - 1s - loss: 537.8448 - mae: 537.8448 - val_loss: 316.5757 - val_mae: 316.5757 - 894ms/epoch - 4ms/step\n",
            "Epoch 19/200\n",
            "250/250 - 1s - loss: 523.1553 - mae: 523.1553 - val_loss: 319.8768 - val_mae: 319.8768 - 1s/epoch - 4ms/step\n",
            "Epoch 20/200\n",
            "250/250 - 1s - loss: 492.0746 - mae: 492.0746 - val_loss: 415.7755 - val_mae: 415.7755 - 970ms/epoch - 4ms/step\n",
            "Epoch 21/200\n",
            "250/250 - 1s - loss: 530.3979 - mae: 530.3979 - val_loss: 425.3672 - val_mae: 425.3672 - 1s/epoch - 4ms/step\n",
            "Epoch 22/200\n",
            "250/250 - 1s - loss: 497.4564 - mae: 497.4564 - val_loss: 372.5680 - val_mae: 372.5680 - 1s/epoch - 4ms/step\n",
            "Epoch 23/200\n",
            "250/250 - 1s - loss: 482.9650 - mae: 482.9650 - val_loss: 304.2242 - val_mae: 304.2242 - 1s/epoch - 4ms/step\n",
            "Epoch 24/200\n",
            "250/250 - 1s - loss: 502.5948 - mae: 502.5948 - val_loss: 307.9621 - val_mae: 307.9621 - 1s/epoch - 5ms/step\n",
            "Epoch 25/200\n",
            "250/250 - 1s - loss: 475.1891 - mae: 475.1891 - val_loss: 297.5155 - val_mae: 297.5155 - 1s/epoch - 5ms/step\n",
            "Epoch 26/200\n",
            "250/250 - 1s - loss: 483.5179 - mae: 483.5179 - val_loss: 291.1043 - val_mae: 291.1043 - 1s/epoch - 5ms/step\n",
            "Epoch 27/200\n",
            "250/250 - 1s - loss: 460.9529 - mae: 460.9529 - val_loss: 295.4939 - val_mae: 295.4939 - 1s/epoch - 5ms/step\n",
            "Epoch 28/200\n",
            "250/250 - 1s - loss: 458.8946 - mae: 458.8946 - val_loss: 606.1651 - val_mae: 606.1651 - 1s/epoch - 5ms/step\n",
            "Epoch 29/200\n",
            "250/250 - 1s - loss: 496.3009 - mae: 496.3009 - val_loss: 341.8129 - val_mae: 341.8129 - 1s/epoch - 4ms/step\n",
            "Epoch 30/200\n",
            "250/250 - 1s - loss: 456.3325 - mae: 456.3325 - val_loss: 358.7198 - val_mae: 358.7198 - 1s/epoch - 4ms/step\n",
            "Epoch 31/200\n",
            "250/250 - 1s - loss: 457.7079 - mae: 457.7079 - val_loss: 283.7701 - val_mae: 283.7701 - 932ms/epoch - 4ms/step\n",
            "Epoch 32/200\n",
            "250/250 - 1s - loss: 466.8945 - mae: 466.8945 - val_loss: 278.5840 - val_mae: 278.5840 - 959ms/epoch - 4ms/step\n",
            "Epoch 33/200\n",
            "250/250 - 1s - loss: 448.2113 - mae: 448.2113 - val_loss: 864.5034 - val_mae: 864.5034 - 975ms/epoch - 4ms/step\n",
            "Epoch 34/200\n",
            "250/250 - 1s - loss: 437.4772 - mae: 437.4772 - val_loss: 470.1258 - val_mae: 470.1258 - 1s/epoch - 4ms/step\n",
            "Epoch 35/200\n",
            "250/250 - 1s - loss: 428.0403 - mae: 428.0403 - val_loss: 368.4793 - val_mae: 368.4793 - 1s/epoch - 5ms/step\n",
            "Epoch 36/200\n",
            "250/250 - 1s - loss: 422.7340 - mae: 422.7340 - val_loss: 304.8811 - val_mae: 304.8811 - 970ms/epoch - 4ms/step\n",
            "Epoch 37/200\n",
            "250/250 - 1s - loss: 439.4312 - mae: 439.4312 - val_loss: 302.3745 - val_mae: 302.3745 - 973ms/epoch - 4ms/step\n",
            "Epoch 38/200\n",
            "250/250 - 1s - loss: 414.5948 - mae: 414.5948 - val_loss: 262.2105 - val_mae: 262.2105 - 1s/epoch - 4ms/step\n",
            "Epoch 39/200\n",
            "250/250 - 1s - loss: 394.0354 - mae: 394.0354 - val_loss: 255.3777 - val_mae: 255.3777 - 1s/epoch - 4ms/step\n",
            "Epoch 40/200\n",
            "250/250 - 1s - loss: 414.9523 - mae: 414.9523 - val_loss: 261.9906 - val_mae: 261.9906 - 1s/epoch - 4ms/step\n",
            "Epoch 41/200\n",
            "250/250 - 1s - loss: 414.3030 - mae: 414.3030 - val_loss: 474.1501 - val_mae: 474.1501 - 1s/epoch - 4ms/step\n",
            "Epoch 42/200\n",
            "250/250 - 1s - loss: 401.3307 - mae: 401.3307 - val_loss: 411.1475 - val_mae: 411.1475 - 1s/epoch - 5ms/step\n",
            "Epoch 43/200\n",
            "250/250 - 1s - loss: 393.8705 - mae: 393.8705 - val_loss: 261.0240 - val_mae: 261.0240 - 977ms/epoch - 4ms/step\n",
            "Epoch 44/200\n",
            "250/250 - 1s - loss: 362.9834 - mae: 362.9834 - val_loss: 264.0830 - val_mae: 264.0830 - 936ms/epoch - 4ms/step\n",
            "Epoch 45/200\n",
            "250/250 - 1s - loss: 352.5614 - mae: 352.5614 - val_loss: 275.4346 - val_mae: 275.4346 - 1s/epoch - 4ms/step\n",
            "Epoch 46/200\n",
            "250/250 - 1s - loss: 379.2307 - mae: 379.2307 - val_loss: 317.4529 - val_mae: 317.4529 - 1s/epoch - 4ms/step\n",
            "Epoch 47/200\n",
            "250/250 - 1s - loss: 365.7545 - mae: 365.7545 - val_loss: 231.6151 - val_mae: 231.6151 - 988ms/epoch - 4ms/step\n",
            "Epoch 48/200\n",
            "250/250 - 1s - loss: 376.4237 - mae: 376.4237 - val_loss: 461.4119 - val_mae: 461.4119 - 1s/epoch - 5ms/step\n",
            "Epoch 49/200\n",
            "250/250 - 1s - loss: 396.7541 - mae: 396.7541 - val_loss: 231.2411 - val_mae: 231.2411 - 1s/epoch - 4ms/step\n",
            "Epoch 50/200\n",
            "250/250 - 1s - loss: 381.8584 - mae: 381.8584 - val_loss: 371.2227 - val_mae: 371.2227 - 951ms/epoch - 4ms/step\n",
            "Epoch 51/200\n",
            "250/250 - 1s - loss: 347.5875 - mae: 347.5875 - val_loss: 220.4938 - val_mae: 220.4938 - 946ms/epoch - 4ms/step\n",
            "Epoch 52/200\n",
            "250/250 - 1s - loss: 339.3950 - mae: 339.3950 - val_loss: 361.2643 - val_mae: 361.2643 - 1s/epoch - 5ms/step\n",
            "Epoch 53/200\n",
            "250/250 - 1s - loss: 342.4745 - mae: 342.4745 - val_loss: 224.4309 - val_mae: 224.4309 - 1s/epoch - 4ms/step\n",
            "Epoch 54/200\n",
            "250/250 - 1s - loss: 338.3214 - mae: 338.3214 - val_loss: 232.5733 - val_mae: 232.5733 - 1s/epoch - 5ms/step\n",
            "Epoch 55/200\n",
            "250/250 - 1s - loss: 332.3503 - mae: 332.3503 - val_loss: 235.1741 - val_mae: 235.1741 - 1s/epoch - 5ms/step\n",
            "Epoch 56/200\n",
            "250/250 - 1s - loss: 317.2725 - mae: 317.2725 - val_loss: 292.6367 - val_mae: 292.6367 - 1s/epoch - 4ms/step\n",
            "Epoch 57/200\n",
            "250/250 - 1s - loss: 353.6391 - mae: 353.6391 - val_loss: 390.8414 - val_mae: 390.8414 - 953ms/epoch - 4ms/step\n",
            "Epoch 58/200\n",
            "250/250 - 1s - loss: 404.1852 - mae: 404.1852 - val_loss: 239.3186 - val_mae: 239.3186 - 1s/epoch - 4ms/step\n",
            "Epoch 59/200\n",
            "250/250 - 1s - loss: 342.5585 - mae: 342.5585 - val_loss: 330.0436 - val_mae: 330.0436 - 951ms/epoch - 4ms/step\n",
            "Epoch 60/200\n",
            "250/250 - 1s - loss: 313.9910 - mae: 313.9910 - val_loss: 216.8939 - val_mae: 216.8939 - 959ms/epoch - 4ms/step\n",
            "Epoch 61/200\n",
            "250/250 - 1s - loss: 343.6443 - mae: 343.6443 - val_loss: 233.1106 - val_mae: 233.1106 - 993ms/epoch - 4ms/step\n",
            "Epoch 62/200\n",
            "250/250 - 1s - loss: 320.3593 - mae: 320.3593 - val_loss: 208.7397 - val_mae: 208.7397 - 1s/epoch - 5ms/step\n",
            "Epoch 63/200\n",
            "250/250 - 1s - loss: 335.6338 - mae: 335.6338 - val_loss: 209.9670 - val_mae: 209.9670 - 1s/epoch - 4ms/step\n",
            "Epoch 64/200\n",
            "250/250 - 1s - loss: 312.9354 - mae: 312.9354 - val_loss: 215.1393 - val_mae: 215.1393 - 1s/epoch - 4ms/step\n",
            "Epoch 65/200\n",
            "250/250 - 1s - loss: 324.7216 - mae: 324.7216 - val_loss: 202.2307 - val_mae: 202.2307 - 1s/epoch - 4ms/step\n",
            "Epoch 66/200\n",
            "250/250 - 1s - loss: 321.3961 - mae: 321.3961 - val_loss: 213.2034 - val_mae: 213.2034 - 1s/epoch - 4ms/step\n",
            "Epoch 67/200\n",
            "250/250 - 1s - loss: 312.8722 - mae: 312.8722 - val_loss: 199.5761 - val_mae: 199.5761 - 1s/epoch - 4ms/step\n",
            "Epoch 68/200\n",
            "250/250 - 1s - loss: 351.0661 - mae: 351.0661 - val_loss: 217.4963 - val_mae: 217.4963 - 1s/epoch - 4ms/step\n",
            "Epoch 69/200\n",
            "250/250 - 1s - loss: 338.4772 - mae: 338.4772 - val_loss: 307.1097 - val_mae: 307.1097 - 1s/epoch - 4ms/step\n",
            "Epoch 70/200\n",
            "250/250 - 1s - loss: 307.7563 - mae: 307.7563 - val_loss: 240.7096 - val_mae: 240.7096 - 993ms/epoch - 4ms/step\n",
            "Epoch 71/200\n",
            "250/250 - 1s - loss: 283.0115 - mae: 283.0115 - val_loss: 496.5446 - val_mae: 496.5446 - 1s/epoch - 4ms/step\n",
            "Epoch 72/200\n",
            "250/250 - 1s - loss: 329.1904 - mae: 329.1904 - val_loss: 296.2143 - val_mae: 296.2143 - 1s/epoch - 4ms/step\n",
            "Epoch 73/200\n",
            "250/250 - 1s - loss: 315.8856 - mae: 315.8856 - val_loss: 343.4571 - val_mae: 343.4571 - 1s/epoch - 5ms/step\n",
            "Epoch 74/200\n",
            "250/250 - 1s - loss: 306.2460 - mae: 306.2460 - val_loss: 289.8207 - val_mae: 289.8207 - 1s/epoch - 5ms/step\n",
            "Epoch 75/200\n",
            "250/250 - 1s - loss: 296.5231 - mae: 296.5231 - val_loss: 197.9802 - val_mae: 197.9802 - 977ms/epoch - 4ms/step\n",
            "Epoch 76/200\n",
            "250/250 - 1s - loss: 280.2742 - mae: 280.2742 - val_loss: 195.7366 - val_mae: 195.7366 - 1s/epoch - 4ms/step\n",
            "Epoch 77/200\n",
            "250/250 - 1s - loss: 282.7368 - mae: 282.7368 - val_loss: 187.8673 - val_mae: 187.8673 - 1s/epoch - 5ms/step\n",
            "Epoch 78/200\n",
            "250/250 - 1s - loss: 286.7057 - mae: 286.7057 - val_loss: 189.6963 - val_mae: 189.6963 - 959ms/epoch - 4ms/step\n",
            "Epoch 79/200\n",
            "250/250 - 1s - loss: 292.7723 - mae: 292.7723 - val_loss: 196.3600 - val_mae: 196.3600 - 999ms/epoch - 4ms/step\n",
            "Epoch 80/200\n",
            "250/250 - 1s - loss: 292.7645 - mae: 292.7645 - val_loss: 227.8746 - val_mae: 227.8746 - 1s/epoch - 5ms/step\n",
            "Epoch 81/200\n",
            "250/250 - 1s - loss: 286.5132 - mae: 286.5132 - val_loss: 189.4285 - val_mae: 189.4285 - 1s/epoch - 5ms/step\n",
            "Epoch 82/200\n",
            "250/250 - 1s - loss: 282.1342 - mae: 282.1342 - val_loss: 197.6293 - val_mae: 197.6293 - 1s/epoch - 5ms/step\n",
            "Epoch 83/200\n",
            "250/250 - 1s - loss: 280.8094 - mae: 280.8094 - val_loss: 194.6736 - val_mae: 194.6736 - 1s/epoch - 4ms/step\n",
            "Epoch 84/200\n",
            "250/250 - 1s - loss: 279.3245 - mae: 279.3245 - val_loss: 233.0620 - val_mae: 233.0620 - 1s/epoch - 5ms/step\n",
            "Epoch 85/200\n",
            "250/250 - 1s - loss: 280.8102 - mae: 280.8102 - val_loss: 199.0898 - val_mae: 199.0898 - 950ms/epoch - 4ms/step\n",
            "Epoch 86/200\n",
            "250/250 - 1s - loss: 265.9262 - mae: 265.9262 - val_loss: 226.1767 - val_mae: 226.1767 - 1s/epoch - 4ms/step\n",
            "Epoch 87/200\n",
            "250/250 - 1s - loss: 280.0520 - mae: 280.0520 - val_loss: 236.5433 - val_mae: 236.5433 - 1s/epoch - 4ms/step\n",
            "Epoch 88/200\n",
            "250/250 - 1s - loss: 284.6863 - mae: 284.6863 - val_loss: 177.7380 - val_mae: 177.7380 - 979ms/epoch - 4ms/step\n",
            "Epoch 89/200\n",
            "250/250 - 1s - loss: 274.8132 - mae: 274.8132 - val_loss: 232.7706 - val_mae: 232.7706 - 995ms/epoch - 4ms/step\n",
            "Epoch 90/200\n",
            "250/250 - 1s - loss: 272.2750 - mae: 272.2750 - val_loss: 214.6984 - val_mae: 214.6984 - 1s/epoch - 5ms/step\n",
            "Epoch 91/200\n",
            "250/250 - 1s - loss: 274.8870 - mae: 274.8870 - val_loss: 180.6136 - val_mae: 180.6136 - 1s/epoch - 5ms/step\n",
            "Epoch 92/200\n",
            "250/250 - 1s - loss: 277.0834 - mae: 277.0834 - val_loss: 199.0186 - val_mae: 199.0186 - 977ms/epoch - 4ms/step\n",
            "Epoch 93/200\n",
            "250/250 - 1s - loss: 257.3435 - mae: 257.3435 - val_loss: 175.3710 - val_mae: 175.3710 - 966ms/epoch - 4ms/step\n",
            "Epoch 94/200\n",
            "250/250 - 1s - loss: 264.0824 - mae: 264.0824 - val_loss: 186.3164 - val_mae: 186.3164 - 975ms/epoch - 4ms/step\n",
            "Epoch 95/200\n",
            "250/250 - 1s - loss: 268.8311 - mae: 268.8311 - val_loss: 187.4957 - val_mae: 187.4957 - 1s/epoch - 4ms/step\n",
            "Epoch 96/200\n",
            "250/250 - 1s - loss: 260.6422 - mae: 260.6422 - val_loss: 201.1098 - val_mae: 201.1098 - 1s/epoch - 5ms/step\n",
            "Epoch 97/200\n",
            "250/250 - 1s - loss: 266.2393 - mae: 266.2393 - val_loss: 174.7384 - val_mae: 174.7384 - 1s/epoch - 5ms/step\n",
            "Epoch 98/200\n",
            "250/250 - 1s - loss: 255.5018 - mae: 255.5018 - val_loss: 339.7941 - val_mae: 339.7941 - 1s/epoch - 4ms/step\n",
            "Epoch 99/200\n",
            "250/250 - 1s - loss: 266.7716 - mae: 266.7716 - val_loss: 173.5305 - val_mae: 173.5305 - 1s/epoch - 4ms/step\n",
            "Epoch 100/200\n",
            "250/250 - 1s - loss: 253.9314 - mae: 253.9314 - val_loss: 200.5978 - val_mae: 200.5978 - 1s/epoch - 5ms/step\n",
            "Epoch 101/200\n",
            "250/250 - 1s - loss: 257.2698 - mae: 257.2698 - val_loss: 201.0085 - val_mae: 201.0085 - 1s/epoch - 5ms/step\n",
            "Epoch 102/200\n",
            "250/250 - 1s - loss: 273.9910 - mae: 273.9910 - val_loss: 185.0933 - val_mae: 185.0933 - 899ms/epoch - 4ms/step\n",
            "Epoch 103/200\n",
            "250/250 - 1s - loss: 257.1992 - mae: 257.1992 - val_loss: 181.3133 - val_mae: 181.3133 - 1s/epoch - 5ms/step\n",
            "Epoch 104/200\n",
            "250/250 - 1s - loss: 255.9036 - mae: 255.9036 - val_loss: 198.4377 - val_mae: 198.4377 - 989ms/epoch - 4ms/step\n",
            "Epoch 105/200\n",
            "250/250 - 1s - loss: 256.4067 - mae: 256.4067 - val_loss: 176.8700 - val_mae: 176.8700 - 1s/epoch - 5ms/step\n",
            "Epoch 106/200\n",
            "250/250 - 1s - loss: 281.9039 - mae: 281.9039 - val_loss: 198.3796 - val_mae: 198.3796 - 1s/epoch - 4ms/step\n",
            "Epoch 107/200\n",
            "250/250 - 1s - loss: 254.8492 - mae: 254.8492 - val_loss: 175.0573 - val_mae: 175.0573 - 1s/epoch - 5ms/step\n",
            "Epoch 108/200\n",
            "250/250 - 1s - loss: 256.9080 - mae: 256.9080 - val_loss: 181.2822 - val_mae: 181.2822 - 1s/epoch - 5ms/step\n",
            "Epoch 109/200\n",
            "250/250 - 1s - loss: 251.5375 - mae: 251.5375 - val_loss: 181.7644 - val_mae: 181.7644 - 1s/epoch - 5ms/step\n",
            "Epoch 110/200\n",
            "250/250 - 1s - loss: 262.0060 - mae: 262.0060 - val_loss: 179.9394 - val_mae: 179.9394 - 1s/epoch - 4ms/step\n",
            "Epoch 111/200\n",
            "250/250 - 1s - loss: 266.6416 - mae: 266.6416 - val_loss: 201.2433 - val_mae: 201.2433 - 1s/epoch - 5ms/step\n",
            "Epoch 112/200\n",
            "250/250 - 1s - loss: 272.9680 - mae: 272.9680 - val_loss: 181.0641 - val_mae: 181.0641 - 1s/epoch - 4ms/step\n",
            "Epoch 113/200\n",
            "250/250 - 1s - loss: 262.5951 - mae: 262.5951 - val_loss: 218.2273 - val_mae: 218.2273 - 972ms/epoch - 4ms/step\n",
            "Epoch 114/200\n",
            "250/250 - 1s - loss: 259.2334 - mae: 259.2334 - val_loss: 172.4062 - val_mae: 172.4062 - 1s/epoch - 5ms/step\n",
            "Epoch 115/200\n",
            "250/250 - 1s - loss: 257.7931 - mae: 257.7931 - val_loss: 178.0912 - val_mae: 178.0912 - 999ms/epoch - 4ms/step\n",
            "Epoch 116/200\n",
            "250/250 - 1s - loss: 256.5093 - mae: 256.5093 - val_loss: 172.6901 - val_mae: 172.6901 - 1s/epoch - 5ms/step\n",
            "Epoch 117/200\n",
            "250/250 - 1s - loss: 249.4390 - mae: 249.4390 - val_loss: 175.2363 - val_mae: 175.2363 - 874ms/epoch - 3ms/step\n",
            "Epoch 118/200\n",
            "250/250 - 1s - loss: 256.9309 - mae: 256.9309 - val_loss: 180.2841 - val_mae: 180.2841 - 1s/epoch - 5ms/step\n",
            "Epoch 119/200\n",
            "250/250 - 1s - loss: 248.8270 - mae: 248.8270 - val_loss: 171.9249 - val_mae: 171.9249 - 1s/epoch - 4ms/step\n",
            "Epoch 120/200\n",
            "250/250 - 1s - loss: 252.0282 - mae: 252.0282 - val_loss: 223.0462 - val_mae: 223.0462 - 1s/epoch - 4ms/step\n",
            "Epoch 121/200\n",
            "250/250 - 1s - loss: 256.9170 - mae: 256.9170 - val_loss: 189.1933 - val_mae: 189.1933 - 995ms/epoch - 4ms/step\n",
            "Epoch 122/200\n",
            "250/250 - 1s - loss: 251.8706 - mae: 251.8706 - val_loss: 173.5161 - val_mae: 173.5161 - 1s/epoch - 4ms/step\n",
            "Epoch 123/200\n",
            "250/250 - 1s - loss: 252.3905 - mae: 252.3905 - val_loss: 172.2070 - val_mae: 172.2070 - 1s/epoch - 4ms/step\n",
            "Epoch 124/200\n",
            "250/250 - 1s - loss: 250.0735 - mae: 250.0735 - val_loss: 177.0044 - val_mae: 177.0044 - 1s/epoch - 4ms/step\n",
            "Epoch 125/200\n",
            "250/250 - 1s - loss: 244.2144 - mae: 244.2144 - val_loss: 222.0978 - val_mae: 222.0978 - 1s/epoch - 4ms/step\n",
            "Epoch 126/200\n",
            "250/250 - 1s - loss: 256.3424 - mae: 256.3424 - val_loss: 172.1049 - val_mae: 172.1049 - 1s/epoch - 4ms/step\n",
            "Epoch 127/200\n",
            "250/250 - 1s - loss: 247.7731 - mae: 247.7731 - val_loss: 179.4041 - val_mae: 179.4041 - 1s/epoch - 4ms/step\n",
            "Epoch 128/200\n",
            "250/250 - 1s - loss: 262.7135 - mae: 262.7135 - val_loss: 191.0849 - val_mae: 191.0849 - 1s/epoch - 5ms/step\n",
            "Epoch 129/200\n",
            "250/250 - 1s - loss: 253.3251 - mae: 253.3251 - val_loss: 184.6814 - val_mae: 184.6814 - 1s/epoch - 4ms/step\n",
            "Epoch 130/200\n",
            "250/250 - 1s - loss: 261.6838 - mae: 261.6838 - val_loss: 225.5718 - val_mae: 225.5718 - 1s/epoch - 5ms/step\n",
            "Epoch 131/200\n",
            "250/250 - 1s - loss: 251.0507 - mae: 251.0507 - val_loss: 171.0994 - val_mae: 171.0994 - 979ms/epoch - 4ms/step\n",
            "Epoch 132/200\n",
            "250/250 - 1s - loss: 250.1516 - mae: 250.1516 - val_loss: 181.9967 - val_mae: 181.9967 - 1s/epoch - 4ms/step\n",
            "Epoch 133/200\n",
            "250/250 - 1s - loss: 255.3081 - mae: 255.3081 - val_loss: 182.1382 - val_mae: 182.1382 - 997ms/epoch - 4ms/step\n",
            "Epoch 134/200\n",
            "250/250 - 1s - loss: 256.8398 - mae: 256.8398 - val_loss: 232.9097 - val_mae: 232.9097 - 1s/epoch - 4ms/step\n",
            "Epoch 135/200\n",
            "250/250 - 1s - loss: 256.4408 - mae: 256.4408 - val_loss: 172.8008 - val_mae: 172.8008 - 1s/epoch - 4ms/step\n",
            "Epoch 136/200\n",
            "250/250 - 1s - loss: 249.6026 - mae: 249.6026 - val_loss: 172.0029 - val_mae: 172.0029 - 959ms/epoch - 4ms/step\n",
            "Epoch 137/200\n",
            "250/250 - 1s - loss: 256.4828 - mae: 256.4828 - val_loss: 178.2242 - val_mae: 178.2242 - 1s/epoch - 4ms/step\n",
            "Epoch 138/200\n",
            "250/250 - 1s - loss: 262.5755 - mae: 262.5755 - val_loss: 206.5869 - val_mae: 206.5869 - 1s/epoch - 5ms/step\n",
            "Epoch 139/200\n",
            "250/250 - 1s - loss: 258.9283 - mae: 258.9283 - val_loss: 169.9511 - val_mae: 169.9511 - 1s/epoch - 5ms/step\n",
            "Epoch 140/200\n",
            "250/250 - 1s - loss: 257.4245 - mae: 257.4245 - val_loss: 170.2285 - val_mae: 170.2285 - 1s/epoch - 5ms/step\n",
            "Epoch 141/200\n",
            "250/250 - 1s - loss: 245.4507 - mae: 245.4507 - val_loss: 170.4817 - val_mae: 170.4817 - 1s/epoch - 5ms/step\n",
            "Epoch 142/200\n",
            "250/250 - 1s - loss: 254.9858 - mae: 254.9858 - val_loss: 195.0892 - val_mae: 195.0892 - 1s/epoch - 4ms/step\n",
            "Epoch 143/200\n",
            "250/250 - 1s - loss: 245.0539 - mae: 245.0539 - val_loss: 169.4085 - val_mae: 169.4085 - 1s/epoch - 4ms/step\n",
            "Epoch 144/200\n",
            "250/250 - 1s - loss: 251.6137 - mae: 251.6137 - val_loss: 192.8477 - val_mae: 192.8477 - 877ms/epoch - 4ms/step\n",
            "Epoch 145/200\n",
            "250/250 - 1s - loss: 248.1785 - mae: 248.1785 - val_loss: 169.7313 - val_mae: 169.7313 - 992ms/epoch - 4ms/step\n",
            "Epoch 146/200\n",
            "250/250 - 1s - loss: 250.6684 - mae: 250.6684 - val_loss: 196.4060 - val_mae: 196.4060 - 1s/epoch - 5ms/step\n",
            "Epoch 147/200\n",
            "250/250 - 1s - loss: 259.8726 - mae: 259.8726 - val_loss: 187.2567 - val_mae: 187.2567 - 1s/epoch - 5ms/step\n",
            "Epoch 148/200\n",
            "250/250 - 1s - loss: 242.2078 - mae: 242.2078 - val_loss: 204.3859 - val_mae: 204.3859 - 1s/epoch - 4ms/step\n",
            "Epoch 149/200\n",
            "250/250 - 1s - loss: 249.1324 - mae: 249.1324 - val_loss: 172.0678 - val_mae: 172.0678 - 1s/epoch - 5ms/step\n",
            "Epoch 150/200\n",
            "250/250 - 1s - loss: 252.8164 - mae: 252.8164 - val_loss: 176.5108 - val_mae: 176.5108 - 968ms/epoch - 4ms/step\n",
            "Epoch 151/200\n",
            "250/250 - 1s - loss: 242.7288 - mae: 242.7288 - val_loss: 197.3122 - val_mae: 197.3122 - 988ms/epoch - 4ms/step\n",
            "Epoch 152/200\n",
            "250/250 - 1s - loss: 244.4570 - mae: 244.4570 - val_loss: 169.1432 - val_mae: 169.1432 - 1s/epoch - 4ms/step\n",
            "Epoch 153/200\n",
            "250/250 - 1s - loss: 247.2366 - mae: 247.2366 - val_loss: 211.8390 - val_mae: 211.8390 - 1s/epoch - 5ms/step\n",
            "Epoch 154/200\n",
            "250/250 - 1s - loss: 251.4840 - mae: 251.4840 - val_loss: 221.3774 - val_mae: 221.3774 - 966ms/epoch - 4ms/step\n",
            "Epoch 155/200\n",
            "250/250 - 1s - loss: 248.0830 - mae: 248.0830 - val_loss: 205.1396 - val_mae: 205.1396 - 988ms/epoch - 4ms/step\n",
            "Epoch 156/200\n",
            "250/250 - 1s - loss: 245.9918 - mae: 245.9918 - val_loss: 179.7659 - val_mae: 179.7659 - 1s/epoch - 4ms/step\n",
            "Epoch 157/200\n",
            "250/250 - 1s - loss: 251.2708 - mae: 251.2708 - val_loss: 198.8667 - val_mae: 198.8667 - 1s/epoch - 4ms/step\n",
            "Epoch 158/200\n",
            "250/250 - 1s - loss: 246.8744 - mae: 246.8744 - val_loss: 169.1167 - val_mae: 169.1167 - 1s/epoch - 5ms/step\n",
            "Epoch 159/200\n",
            "250/250 - 1s - loss: 242.0529 - mae: 242.0529 - val_loss: 195.3030 - val_mae: 195.3030 - 971ms/epoch - 4ms/step\n",
            "Epoch 160/200\n",
            "250/250 - 1s - loss: 253.5675 - mae: 253.5675 - val_loss: 199.3245 - val_mae: 199.3245 - 972ms/epoch - 4ms/step\n",
            "Epoch 161/200\n",
            "250/250 - 1s - loss: 243.7853 - mae: 243.7853 - val_loss: 170.6260 - val_mae: 170.6260 - 1s/epoch - 4ms/step\n",
            "Epoch 162/200\n",
            "250/250 - 1s - loss: 250.0645 - mae: 250.0645 - val_loss: 174.2141 - val_mae: 174.2141 - 986ms/epoch - 4ms/step\n",
            "Epoch 163/200\n",
            "250/250 - 1s - loss: 245.7447 - mae: 245.7447 - val_loss: 242.7073 - val_mae: 242.7073 - 1s/epoch - 5ms/step\n",
            "Epoch 164/200\n",
            "250/250 - 1s - loss: 245.7536 - mae: 245.7536 - val_loss: 179.6671 - val_mae: 179.6671 - 1s/epoch - 5ms/step\n",
            "Epoch 165/200\n",
            "250/250 - 1s - loss: 245.5566 - mae: 245.5566 - val_loss: 207.0341 - val_mae: 207.0341 - 1s/epoch - 4ms/step\n",
            "Epoch 166/200\n",
            "250/250 - 1s - loss: 251.2707 - mae: 251.2707 - val_loss: 169.6159 - val_mae: 169.6159 - 1s/epoch - 4ms/step\n",
            "Epoch 167/200\n",
            "250/250 - 1s - loss: 239.8980 - mae: 239.8980 - val_loss: 173.0966 - val_mae: 173.0966 - 1s/epoch - 4ms/step\n",
            "Epoch 168/200\n",
            "250/250 - 1s - loss: 241.0902 - mae: 241.0902 - val_loss: 174.4737 - val_mae: 174.4737 - 988ms/epoch - 4ms/step\n",
            "Epoch 169/200\n",
            "250/250 - 1s - loss: 247.2624 - mae: 247.2624 - val_loss: 185.1912 - val_mae: 185.1912 - 1s/epoch - 4ms/step\n",
            "Epoch 170/200\n",
            "250/250 - 1s - loss: 240.0641 - mae: 240.0641 - val_loss: 172.4323 - val_mae: 172.4323 - 1s/epoch - 5ms/step\n",
            "Epoch 171/200\n",
            "250/250 - 1s - loss: 242.2137 - mae: 242.2137 - val_loss: 195.6649 - val_mae: 195.6649 - 1s/epoch - 4ms/step\n",
            "Epoch 172/200\n",
            "250/250 - 1s - loss: 244.0597 - mae: 244.0597 - val_loss: 170.2010 - val_mae: 170.2010 - 1s/epoch - 4ms/step\n",
            "Epoch 173/200\n",
            "250/250 - 1s - loss: 245.9915 - mae: 245.9915 - val_loss: 172.6493 - val_mae: 172.6493 - 1s/epoch - 5ms/step\n",
            "Epoch 174/200\n",
            "250/250 - 1s - loss: 243.9711 - mae: 243.9711 - val_loss: 173.1370 - val_mae: 173.1370 - 1s/epoch - 4ms/step\n",
            "Epoch 175/200\n",
            "250/250 - 1s - loss: 242.8221 - mae: 242.8221 - val_loss: 170.9322 - val_mae: 170.9322 - 1s/epoch - 5ms/step\n",
            "Epoch 176/200\n",
            "250/250 - 1s - loss: 243.6988 - mae: 243.6988 - val_loss: 172.7741 - val_mae: 172.7741 - 1s/epoch - 4ms/step\n",
            "Epoch 177/200\n",
            "250/250 - 1s - loss: 242.2008 - mae: 242.2008 - val_loss: 170.1052 - val_mae: 170.1052 - 1s/epoch - 5ms/step\n",
            "Epoch 178/200\n",
            "250/250 - 1s - loss: 242.4278 - mae: 242.4278 - val_loss: 168.6489 - val_mae: 168.6489 - 1s/epoch - 4ms/step\n",
            "Epoch 179/200\n",
            "250/250 - 1s - loss: 244.6698 - mae: 244.6698 - val_loss: 177.0964 - val_mae: 177.0964 - 1s/epoch - 5ms/step\n",
            "Epoch 180/200\n",
            "250/250 - 1s - loss: 240.7843 - mae: 240.7843 - val_loss: 208.8759 - val_mae: 208.8759 - 1s/epoch - 4ms/step\n",
            "Epoch 181/200\n",
            "250/250 - 1s - loss: 245.0370 - mae: 245.0370 - val_loss: 195.8142 - val_mae: 195.8142 - 1s/epoch - 5ms/step\n",
            "Epoch 182/200\n",
            "250/250 - 1s - loss: 247.9386 - mae: 247.9386 - val_loss: 168.4711 - val_mae: 168.4711 - 1s/epoch - 5ms/step\n",
            "Epoch 183/200\n",
            "250/250 - 1s - loss: 245.3948 - mae: 245.3948 - val_loss: 183.4353 - val_mae: 183.4353 - 1s/epoch - 5ms/step\n",
            "Epoch 184/200\n",
            "250/250 - 1s - loss: 244.6161 - mae: 244.6161 - val_loss: 176.4944 - val_mae: 176.4944 - 1s/epoch - 4ms/step\n",
            "Epoch 185/200\n",
            "250/250 - 1s - loss: 245.0735 - mae: 245.0735 - val_loss: 182.1682 - val_mae: 182.1682 - 988ms/epoch - 4ms/step\n",
            "Epoch 186/200\n",
            "250/250 - 1s - loss: 240.3292 - mae: 240.3292 - val_loss: 192.2399 - val_mae: 192.2399 - 1s/epoch - 4ms/step\n",
            "Epoch 187/200\n",
            "250/250 - 1s - loss: 248.4580 - mae: 248.4580 - val_loss: 169.4800 - val_mae: 169.4800 - 974ms/epoch - 4ms/step\n",
            "Epoch 188/200\n",
            "250/250 - 1s - loss: 246.5645 - mae: 246.5645 - val_loss: 168.7118 - val_mae: 168.7118 - 1s/epoch - 5ms/step\n",
            "Epoch 189/200\n",
            "250/250 - 1s - loss: 245.3824 - mae: 245.3824 - val_loss: 199.7333 - val_mae: 199.7333 - 1s/epoch - 5ms/step\n",
            "Epoch 190/200\n",
            "250/250 - 1s - loss: 247.5215 - mae: 247.5215 - val_loss: 170.6964 - val_mae: 170.6964 - 969ms/epoch - 4ms/step\n",
            "Epoch 191/200\n",
            "250/250 - 1s - loss: 240.0464 - mae: 240.0464 - val_loss: 213.2355 - val_mae: 213.2355 - 1s/epoch - 4ms/step\n",
            "Epoch 192/200\n",
            "250/250 - 1s - loss: 248.2856 - mae: 248.2856 - val_loss: 172.5016 - val_mae: 172.5016 - 1s/epoch - 5ms/step\n",
            "Epoch 193/200\n",
            "250/250 - 1s - loss: 248.5441 - mae: 248.5441 - val_loss: 173.0884 - val_mae: 173.0884 - 1s/epoch - 5ms/step\n",
            "Epoch 194/200\n",
            "250/250 - 1s - loss: 246.0228 - mae: 246.0228 - val_loss: 271.5690 - val_mae: 271.5690 - 1s/epoch - 4ms/step\n",
            "Epoch 195/200\n",
            "250/250 - 1s - loss: 251.9696 - mae: 251.9696 - val_loss: 194.6193 - val_mae: 194.6193 - 1s/epoch - 5ms/step\n",
            "Epoch 196/200\n",
            "250/250 - 1s - loss: 244.2473 - mae: 244.2473 - val_loss: 199.1005 - val_mae: 199.1005 - 1s/epoch - 4ms/step\n",
            "Epoch 197/200\n",
            "250/250 - 1s - loss: 241.1776 - mae: 241.1776 - val_loss: 182.7575 - val_mae: 182.7575 - 1s/epoch - 4ms/step\n",
            "Epoch 198/200\n",
            "250/250 - 1s - loss: 240.3710 - mae: 240.3710 - val_loss: 172.8051 - val_mae: 172.8051 - 1s/epoch - 5ms/step\n",
            "Epoch 199/200\n",
            "250/250 - 1s - loss: 242.8319 - mae: 242.8319 - val_loss: 191.4247 - val_mae: 191.4247 - 1s/epoch - 5ms/step\n",
            "Epoch 200/200\n",
            "250/250 - 1s - loss: 239.9707 - mae: 239.9707 - val_loss: 187.8253 - val_mae: 187.8253 - 977ms/epoch - 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM 모델 평가"
      ],
      "metadata": {
        "id": "OKJKCOAk-feK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ev = model.evaluate(x_test,y_test,verbose = 0)\n",
        "print(f\"손실함수 : {ev[0]}, MAE : {ev[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH5bGxz884Y5",
        "outputId": "33f3e7c6-01c1-4ea0-c67d-a531429714cc"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "손실함수 : 187.8253173828125, MAE : 187.8253173828125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM모델로 예측 수행"
      ],
      "metadata": {
        "id": "Ln2jadX0_ECa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred =  model.predict(x_test)\n",
        "print(f\"평균절댓값 백분율 오차(MAPE) : {sum(abs(y_test-pred)/y_test)/len(x_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkBbKuWR-6LB",
        "outputId": "85f2b901-2e02-491f-c6ee-982f6f964c6a"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균절댓값 백분율 오차(MAPE) : [0.02276638]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습곡선"
      ],
      "metadata": {
        "id": "fav9eqiT_f7T"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cbKjGSTo_XdZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}