{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f583fb5-ba3b-4f6c-8d70-6ad1f18abfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어를 시퀀스로 처리, 시퀀스 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6963e39-97f5-4e7c-a3e4-15113832b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자연어처리2에서 https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz 경로에서 다운받은\n",
    "# 파일을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8db8cd-af6b-4fd3-b113-d3ec78a1b13b",
   "metadata": {},
   "source": [
    "# 단어를 시퀀스로 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d41ae36-2d51-43c8-afb0-0a0b7d9d6985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 가져오는 부분\n",
    "import urllib.request as req    \n",
    "url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "filename = 'aclImdb_v1.tar.gz'\n",
    "with req.urlopen(url) as f:\n",
    "    with open(filename,'wb') as of:\n",
    "        of.write(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb8edeb9-df92-4520-934d-3b1fdfdf86de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 압축풀기\n",
    "import tarfile\n",
    "with tarfile.open(filename,'r:gz') as tr:\n",
    "    tr.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45fbc936-cb6f-42ef-88fc-160d0b4bb458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 분할 폴더별로 나누기\n",
    "import os, pathlib, shutil, random\n",
    "base_dir = pathlib.Path('aclImdb')\n",
    "val_dir = base_dir / 'val'\n",
    "train_dir = base_dir / 'train'\n",
    "for category in ('neg', 'pos'):\n",
    "    os.makedirs(val_dir / category)\n",
    "    files = os.listdir(train_dir / category)\n",
    "    random.Random(1337).shuffle(files)\n",
    "    num_val_samples = int(0.2*len(files))\n",
    "    val_files = files[-num_val_samples:]\n",
    "    for fname in val_files:\n",
    "        shutil.move(train_dir / category / fname, val_dir / category / fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1e4cb2c-34b8-4175-8fe1-bd5f5d143d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 확보\n",
    "import os, pathlib, shutil, random\n",
    "from tensorflow import keras\n",
    "batch_size = 32\n",
    "train_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",batch_size=batch_size\n",
    ")\n",
    "val_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/val\",batch_size=batch_size\n",
    ")\n",
    "test_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/test\",batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afef4929-e4c1-4c8d-beb7-631d1933ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_only_trains_ds = train_ds.map(lambda x,y : x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ae8351-5beb-4dd5-bfe0-a47844e9b098",
   "metadata": {},
   "source": [
    "#### 정수 시퀀스 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a9db438-925e-4402-a18d-f05e92454a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "max_length = 600\n",
    "max_tokens = 20000\n",
    "text_vectorization =  layers.TextVectorization(\n",
    "    max_tokens = max_tokens,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=max_length\n",
    ")\n",
    "text_vectorization.adapt(text_only_trains_ds)\n",
    "\n",
    "int_train_ds =  train_ds.map(\n",
    "    lambda x, y : (text_vectorization(x),y), num_parallel_calls=4\n",
    ")\n",
    "int_val_ds = val_ds.map(\n",
    "    lambda x, y : (text_vectorization(x),y), num_parallel_calls=4\n",
    ")\n",
    "int_test_ds = test_ds.map(\n",
    "    lambda x, y : (text_vectorization(x),y), num_parallel_calls=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf33c4d-bc9f-4d75-b2aa-16fc7dd8e923",
   "metadata": {},
   "source": [
    "### 원-핫 인코딩된 벡터 시퀀스로 시퀀스 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69044993-47d4-458a-96e4-2a7fb1cf1fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " tf.one_hot_2 (TFOpLambda)   (None, None, 20000)       0         \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 64)               5128448   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,128,513\n",
      "Trainable params: 5,128,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "inputs = keras.Input(shape=(None,), dtype = 'int64')\n",
    "embedded = tf.one_hot(inputs, depth=max_tokens)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model = keras.Model(inputs,outputs)\n",
    "model.compile(optimizer='adam',\n",
    "                    loss = 'binary_crossentropy',\n",
    "                    metrics=['accuracy']\n",
    "                   )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58305b5d-dea5-4a2f-b27b-b61d11d1137c",
   "metadata": {},
   "source": [
    "#### 첫번재 시퀀스 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1df81e1-18e4-4421-b1e3-0cc683573f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 23/625 [>.............................] - ETA: 2:31:20 - loss: 0.6936 - accuracy: 0.4810"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = [\n",
    "    keras.callbacks.ModelCheckpoint('one_hot_bidir_lstm.keras', save_best_only=True)\n",
    "]\n",
    "model.fit(int_train_ds,validation_data=int_val_ds, epochs=10,callbacks=callback)\n",
    "print(f\"테스트 정확도 : {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb7e0dd-20fa-4f38-ae22-50562477bd17",
   "metadata": {},
   "source": [
    "#### 단어임베딩\n",
    "#### 임베딩 층으로 단어 임베딩 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9565ba-64ab-4631-b477-7eef91c2ce92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
