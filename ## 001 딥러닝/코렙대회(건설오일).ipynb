{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41d0d3b2-d898-4e5c-8fa4-8ddc375e9cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b94487cd-35e7-43b6-a927-1178c7d79dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS': 30,\n",
    "    'LEARNING_RATE':1e-2,\n",
    "    'BATCH_SIZE':256,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eae2b110-948c-472a-9807-1965cebbaf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "localpath = 'D:/leeky_ai/대회/건설기계오일/open/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3918450-4cb8-4a85-862f-46311ae5eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(localpath+\"train.csv\")\n",
    "test =  pd.read_csv(localpath+\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58df527-34f6-490d-88be-6511be8a160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04bbc0b1-9b4c-49cd-843a-8011d032c0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['COMPONENT_ARBITRARY', 'YEAR']\n",
    "# Inference(실제 진단 환경)에 사용하는 컬럼\n",
    "test_stage_features = ['COMPONENT_ARBITRARY', 'ANONYMOUS_1', 'YEAR' , 'ANONYMOUS_2', 'AG', 'CO', 'CR', 'CU', 'FE', 'H2O', 'MN', 'MO', 'NI', 'PQINDEX', 'TI', 'V', 'V40', 'ZN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "628fe21a-7a5b-4f51-af10-631f2e93a7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(0)\n",
    "test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fada761d-ceb6-4033-8938-35374f5b4834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train.describe()\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.boxplot(data = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2967357-3d0b-458d-a220-d5131a5d7506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>COMPONENT_ARBITRARY</th>\n",
       "      <th>ANONYMOUS_1</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ANONYMOUS_2</th>\n",
       "      <th>AG</th>\n",
       "      <th>CO</th>\n",
       "      <th>CR</th>\n",
       "      <th>CU</th>\n",
       "      <th>FE</th>\n",
       "      <th>H2O</th>\n",
       "      <th>MN</th>\n",
       "      <th>MO</th>\n",
       "      <th>NI</th>\n",
       "      <th>PQINDEX</th>\n",
       "      <th>TI</th>\n",
       "      <th>V</th>\n",
       "      <th>V40</th>\n",
       "      <th>ZN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>COMPONENT1</td>\n",
       "      <td>2192</td>\n",
       "      <td>2016</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91.3</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>COMPONENT3</td>\n",
       "      <td>2794</td>\n",
       "      <td>2011</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2732</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>126.9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>COMPONENT2</td>\n",
       "      <td>1982</td>\n",
       "      <td>2010</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.3</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>COMPONENT3</td>\n",
       "      <td>1404</td>\n",
       "      <td>2009</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142.8</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>COMPONENT2</td>\n",
       "      <td>8225</td>\n",
       "      <td>2013</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.4</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID COMPONENT_ARBITRARY  ANONYMOUS_1  YEAR  ANONYMOUS_2  AG  CO  CR  \\\n",
       "0  TEST_0000          COMPONENT1         2192  2016          200   0   0   0   \n",
       "1  TEST_0001          COMPONENT3         2794  2011          200   0   0   2   \n",
       "2  TEST_0002          COMPONENT2         1982  2010          200   0   0   0   \n",
       "3  TEST_0003          COMPONENT3         1404  2009          200   0   0   3   \n",
       "4  TEST_0004          COMPONENT2         8225  2013          200   0   0   0   \n",
       "\n",
       "   CU   FE  H2O  MN  MO  NI  PQINDEX  TI  V    V40    ZN  \n",
       "0   1   12  0.0   0   0   0       10   0  0   91.3  1091  \n",
       "1   1  278  0.0   3   0   0     2732   1  0  126.9    12  \n",
       "2  16    5  0.0   0   0   0       11   0  0   44.3   714  \n",
       "3   4  163  0.0   4   3   0     8007   0  0  142.8    94  \n",
       "4   6   13  0.0   0   0   0       16   0  0   63.4   469  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f9cdb19-c022-4ea8-9ec5-ec4a178eeff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "all_X = train.drop(['ID', 'Y_LABEL'], axis = 1)\n",
    "all_y = train['Y_LABEL']\n",
    "test = test.drop(['ID'], axis = 1)\n",
    "train_X, val_X, train_y, val_y = train_test_split(all_X, all_y, test_size=0.2, random_state=CFG['SEED'], stratify=all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73d5fa50-557a-4dd0-b1db-e478d7ce0f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11276, 52), (2819, 52), (11276,), (2819,))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape , val_X.shape, train_y.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3df94acb-7e0b-4a16-9343-b974cb236209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "def get_values(value):\n",
    "    return value.values.reshape(-1, 1)\n",
    "\n",
    "for col in train_X.columns:\n",
    "    if col not in categorical_features:\n",
    "        scaler = RobustScaler()\n",
    "        train_X[col] = scaler.fit_transform(get_values(train_X[col]))\n",
    "        val_X[col] = scaler.transform(get_values(val_X[col]))\n",
    "        if col in test.columns:\n",
    "            test[col] = scaler.transform(get_values(test[col]))\n",
    "            \n",
    "le = LabelEncoder()\n",
    "for col in categorical_features:    \n",
    "    train_X[col] = le.fit_transform(train_X[col])\n",
    "    val_X[col] = le.transform(val_X[col])\n",
    "    if col in test.columns:\n",
    "        test[col] = le.transform(test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7900a8da-f8a7-451c-ab89-5e8bed726a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPONENT_ARBITRARY</th>\n",
       "      <th>ANONYMOUS_1</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ANONYMOUS_2</th>\n",
       "      <th>AG</th>\n",
       "      <th>CO</th>\n",
       "      <th>CR</th>\n",
       "      <th>CU</th>\n",
       "      <th>FE</th>\n",
       "      <th>H2O</th>\n",
       "      <th>MN</th>\n",
       "      <th>MO</th>\n",
       "      <th>NI</th>\n",
       "      <th>PQINDEX</th>\n",
       "      <th>TI</th>\n",
       "      <th>V</th>\n",
       "      <th>V40</th>\n",
       "      <th>ZN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.014439</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.1875</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.105882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.305215</td>\n",
       "      <td>0.527290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.265952</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.1875</td>\n",
       "      <td>1.896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.905882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.240798</td>\n",
       "      <td>-0.470860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.112250</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>-0.288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.026074</td>\n",
       "      <td>0.178538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.381463</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.935294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>-0.395005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.795529</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.070588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.733129</td>\n",
       "      <td>-0.048104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COMPONENT_ARBITRARY  ANONYMOUS_1  YEAR  ANONYMOUS_2   AG   CO        CR  \\\n",
       "0                    0    -0.014439     9          0.0  0.0  0.0 -0.333333   \n",
       "1                    2     0.265952     4          0.0  0.0  0.0  0.333333   \n",
       "2                    1    -0.112250     3          0.0  0.0  0.0 -0.333333   \n",
       "3                    2    -0.381463     2          0.0  0.0  0.0  0.666667   \n",
       "4                    1     2.795529     6          0.0  0.0  0.0 -0.333333   \n",
       "\n",
       "       CU     FE  H2O   MN        MO   NI    PQINDEX   TI    V       V40  \\\n",
       "0 -0.1875 -0.232  0.0 -0.5 -0.142857  0.0  -0.105882  0.0  0.0 -0.305215   \n",
       "1 -0.1875  1.896  0.0  1.0 -0.142857  0.0  15.905882  1.0  0.0  0.240798   \n",
       "2  0.7500 -0.288  0.0 -0.5 -0.142857  0.0  -0.100000  0.0  0.0 -1.026074   \n",
       "3  0.0000  0.976  0.0  1.5  0.285714  0.0  46.935294  0.0  0.0  0.484663   \n",
       "4  0.1250 -0.224  0.0 -0.5 -0.142857  0.0  -0.070588  0.0  0.0 -0.733129   \n",
       "\n",
       "         ZN  \n",
       "0  0.527290  \n",
       "1 -0.470860  \n",
       "2  0.178538  \n",
       "3 -0.395005  \n",
       "4 -0.048104  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be253aef-4927-4eaa-aab9-ceab7c7eb7d2",
   "metadata": {},
   "source": [
    "# 지식증류(Knowledge Distillation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "191acc70-4cd6-471a-aee9-816ea9ea81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "df0b522d-b584-4418-853f-fe76396cf34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distillation(keras.Model):\n",
    "    '''\n",
    "        사전훈련된 교사모델\n",
    "        훈련할 학생 모델\n",
    "        손실함수\n",
    "        소프트 학생 예측과 소프트 교사 라벨간의 차이에 대한 증류 손실 함수와 온도 스케일링 함수\n",
    "        학생에게 가중치를 주는 alpha factor 요소와 증류 손실\n",
    "        학생을 위한 최적화 도구(optimizer fo th student,선택옵션)와 퍼포먼스 측정을 위한 metrics\n",
    "        \n",
    "        교사와 학생모두에 대해서 forward를  수행하고 그 결과 alpha와(1-alpha)로 student_loss 와 distillation_lossby lapha 가중치로\n",
    "        손실을 계산\n",
    "        backward를 수행\n",
    "    '''\n",
    "    def __init__(self, student, teacher):\n",
    "        super(Distillation,self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "            \n",
    "    def compile(self\n",
    "        ,optimizer='adam', metrics='accuracy'\n",
    "                , student_loss_fn = keras.losses.binary_crossentropy\n",
    "                , distillation_loss_fn = keras.losses.binary_crossentropy\n",
    "                , alpha=0.1,temperature=3        \n",
    "    ):\n",
    "        super(Distillation,self).compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        # 데이터 언 패킹\n",
    "        tx,sx, y = data\n",
    "        teacher_predictioons = self.teacher.predict(tx)\n",
    "        # 자동미분\n",
    "        with tf.GradientTape() as tape:\n",
    "            # 학생의 전방 계산\n",
    "            student_predictions = self.student.predict(sx)\n",
    "            # losses 계산\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                tf.nn.softmax(teacher_predictioons / self.temperature, axis=1),\n",
    "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
    "            )\n",
    "            loss = self.alpha*student_loss+(1-self.alpha) * distillation_loss\n",
    "        # Gradients 계산\n",
    "        trainable_vars =  self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss,trainable_vars)\n",
    "        \n",
    "        # 가중치 업데이트\n",
    "        self.optimizer.apply_gradients(zip(gradients,trainable_vars))\n",
    "        \n",
    "        # 메트릭 업데이트\n",
    "        self.compiled_metrics.update_state(y,student_predictions)\n",
    "        \n",
    "        # 결과 리턴\n",
    "        results = {m.name:m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\":student_loss,'distillation_loss' :distillation_loss}\n",
    "        )\n",
    "        return result\n",
    "    def test_step(self, data):\n",
    "        x,y = data\n",
    "        y_prediction = self.student.predict(x)\n",
    "        student_loss = self.student_loss_fn(y,y_prediction)\n",
    "        \n",
    "        self.compiled_metrics.update_state(y,y_prediction)\n",
    "        \n",
    "        results = {m.name:m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\":student_loss}\n",
    "        )\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b8d0f9b3-f731-4bef-bc86-aba4d08c7ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11276, 52)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c0dd5850-763c-4266-a2e7-6e122cec424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교사 모델 생성\n",
    "teacher = keras.Sequential(\n",
    "    [\n",
    "    keras.Input(shape=(52,))\n",
    "    ,layers.Dense(256)\n",
    "    ,layers.BatchNormalization()\n",
    "    ,layers.LeakyReLU()\n",
    "    ,layers.Dense(1024)\n",
    "    ,layers.BatchNormalization()\n",
    "    ,layers.LeakyReLU()\n",
    "    ,layers.Dense(256)\n",
    "    ,layers.BatchNormalization()\n",
    "    ,layers.LeakyReLU()\n",
    "    ,layers.Dense(1)\n",
    "    ,layers.BatchNormalization()    \n",
    "    ,layers.Activation(activation='sigmoid')\n",
    "    ],\n",
    "    name = 'teacher'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "efaee730-9bc0-4392-984e-f81ce57a4dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6041, 18)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f9cfcdd0-b6dd-4a5a-b86c-f38b76656969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학생 모델 생성\n",
    "student = keras.Sequential(\n",
    "    [\n",
    "    keras.Input(shape=(18,))\n",
    "    ,layers.Dense(128)\n",
    "    ,layers.BatchNormalization()\n",
    "    ,layers.LeakyReLU()\n",
    "    ,layers.Dense(512)\n",
    "    ,layers.BatchNormalization()\n",
    "    ,layers.LeakyReLU()\n",
    "    ,layers.Dense(128)\n",
    "    ,layers.BatchNormalization()\n",
    "    ,layers.LeakyReLU()\n",
    "    ,layers.Dense(1)\n",
    "    ,layers.BatchNormalization()    \n",
    "    ,layers.Activation(activation='sigmoid')\n",
    "    ],\n",
    "    name = 'student'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3bc8c824-af19-44f1-ad4b-6ba7f35e3c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 후행비교를 위한 학생 복제\n",
    "student_scatch = keras.models.clone_model(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "514d827c-1888-4c91-af99-e6e06f59eb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# student.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "28786daa-0683-4fc3-a0ab-579438a0a68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "353/353 [==============================] - 4s 9ms/step - loss: 0.2035 - acc: 0.9412 - val_loss: 0.2260 - val_acc: 0.9259\n",
      "Epoch 2/100\n",
      "353/353 [==============================] - 3s 9ms/step - loss: 0.1999 - acc: 0.9428 - val_loss: 0.2069 - val_acc: 0.9344\n",
      "Epoch 3/100\n",
      "353/353 [==============================] - 3s 8ms/step - loss: 0.2002 - acc: 0.9418 - val_loss: 0.2428 - val_acc: 0.9305\n",
      "Epoch 4/100\n",
      "353/353 [==============================] - 3s 8ms/step - loss: 0.1929 - acc: 0.9470 - val_loss: 0.2338 - val_acc: 0.9312\n",
      "Epoch 5/100\n",
      "353/353 [==============================] - 3s 8ms/step - loss: 0.1954 - acc: 0.9445 - val_loss: 0.2216 - val_acc: 0.9276\n",
      "Epoch 6/100\n",
      "353/353 [==============================] - 3s 9ms/step - loss: 0.1992 - acc: 0.9444 - val_loss: 0.2171 - val_acc: 0.9287\n",
      "Epoch 7/100\n",
      "353/353 [==============================] - 3s 9ms/step - loss: 0.1979 - acc: 0.9451 - val_loss: 0.2326 - val_acc: 0.9262\n",
      "Epoch 8/100\n",
      "353/353 [==============================] - 3s 9ms/step - loss: 0.1917 - acc: 0.9458 - val_loss: 0.2033 - val_acc: 0.9369\n",
      "Epoch 9/100\n",
      "353/353 [==============================] - 3s 9ms/step - loss: 0.1925 - acc: 0.9457 - val_loss: 0.2474 - val_acc: 0.9312\n",
      "Epoch 10/100\n",
      "353/353 [==============================] - 3s 9ms/step - loss: 0.1889 - acc: 0.9469 - val_loss: 0.2863 - val_acc: 0.9340\n",
      "Epoch 11/100\n",
      "353/353 [==============================] - 3s 8ms/step - loss: 0.1970 - acc: 0.9441 - val_loss: 0.2231 - val_acc: 0.9326\n",
      "Epoch 12/100\n",
      "353/353 [==============================] - 3s 9ms/step - loss: 0.1907 - acc: 0.9461 - val_loss: 0.2093 - val_acc: 0.9351\n",
      "Epoch 13/100\n",
      "353/353 [==============================] - 3s 9ms/step - loss: 0.1980 - acc: 0.9444 - val_loss: 0.2095 - val_acc: 0.9383\n",
      "Epoch 14/100\n",
      "353/353 [==============================] - 3s 9ms/step - loss: 0.1936 - acc: 0.9458 - val_loss: 0.2004 - val_acc: 0.9411\n",
      "Epoch 15/100\n",
      "353/353 [==============================] - 3s 9ms/step - loss: 0.1901 - acc: 0.9457 - val_loss: 0.2413 - val_acc: 0.9393\n",
      "Epoch 16/100\n",
      "353/353 [==============================] - 3s 9ms/step - loss: 0.1937 - acc: 0.9447 - val_loss: 0.2541 - val_acc: 0.9315\n",
      "Epoch 17/100\n",
      "353/353 [==============================] - 3s 9ms/step - loss: 0.1979 - acc: 0.9439 - val_loss: 0.2089 - val_acc: 0.9358\n",
      "Epoch 18/100\n",
      "353/353 [==============================] - 4s 10ms/step - loss: 0.1910 - acc: 0.9457 - val_loss: 0.2372 - val_acc: 0.9259\n",
      "Epoch 19/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.1868 - acc: 0.9468 - val_loss: 0.2019 - val_acc: 0.9386\n",
      "Epoch 20/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.1923 - acc: 0.9468 - val_loss: 0.2114 - val_acc: 0.9354\n",
      "Epoch 21/100\n",
      "353/353 [==============================] - 3s 9ms/step - loss: 0.1941 - acc: 0.9458 - val_loss: 0.2004 - val_acc: 0.9440\n",
      "Epoch 22/100\n",
      "353/353 [==============================] - 3s 9ms/step - loss: 0.1908 - acc: 0.9449 - val_loss: 0.2602 - val_acc: 0.9184\n",
      "Epoch 23/100\n",
      "353/353 [==============================] - 3s 9ms/step - loss: 0.1910 - acc: 0.9456 - val_loss: 0.2012 - val_acc: 0.9436\n",
      "Epoch 24/100\n",
      "353/353 [==============================] - 3s 9ms/step - loss: 0.1920 - acc: 0.9463 - val_loss: 0.2053 - val_acc: 0.9379\n",
      "Epoch 25/100\n",
      "353/353 [==============================] - 3s 10ms/step - loss: 0.1876 - acc: 0.9471 - val_loss: 0.2031 - val_acc: 0.9383\n",
      "Epoch 26/100\n",
      "353/353 [==============================] - 3s 10ms/step - loss: 0.1875 - acc: 0.9471 - val_loss: 0.1975 - val_acc: 0.9436\n",
      "Epoch 27/100\n",
      "353/353 [==============================] - 3s 10ms/step - loss: 0.1859 - acc: 0.9476 - val_loss: 0.1970 - val_acc: 0.9404\n",
      "Epoch 28/100\n",
      "353/353 [==============================] - 3s 9ms/step - loss: 0.1885 - acc: 0.9472 - val_loss: 0.2036 - val_acc: 0.9379\n",
      "Epoch 29/100\n",
      "353/353 [==============================] - 3s 9ms/step - loss: 0.1874 - acc: 0.9468 - val_loss: 0.1981 - val_acc: 0.9386\n",
      "Epoch 30/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.1861 - acc: 0.9485 - val_loss: 0.2044 - val_acc: 0.9404\n",
      "Epoch 31/100\n",
      "353/353 [==============================] - 3s 9ms/step - loss: 0.1890 - acc: 0.9472 - val_loss: 0.1989 - val_acc: 0.9408\n",
      "Epoch 32/100\n",
      "353/353 [==============================] - 4s 10ms/step - loss: 0.1839 - acc: 0.9479 - val_loss: 0.2102 - val_acc: 0.9422\n",
      "Epoch 33/100\n",
      "353/353 [==============================] - 3s 9ms/step - loss: 0.1871 - acc: 0.9479 - val_loss: 0.2073 - val_acc: 0.9376\n",
      "Epoch 34/100\n",
      "353/353 [==============================] - 4s 10ms/step - loss: 0.1886 - acc: 0.9486 - val_loss: 0.2152 - val_acc: 0.9390\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1970 - acc: 0.9404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19697952270507812, 0.9404044151306152]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 교사모델 훈련\n",
    "teacher.compile(\n",
    "    optimizer=keras.optimizers.Adam()\n",
    "    ,loss = keras.losses.binary_crossentropy\n",
    "    ,metrics=['acc']\n",
    ")\n",
    "callback = [\n",
    "    keras.callbacks.EarlyStopping(patience = 7),\n",
    "    keras.callbacks.ModelCheckpoint('teacher.model.keras',save_best_only=True)\n",
    "]\n",
    "teacher.fit(train_X,train_y,epochs=100,callbacks=callback, validation_data=(val_X,val_y))\n",
    "teacher_loadmodel = keras.models.load_model('teacher.model.keras')\n",
    "teacher_loadmodel.evaluate(val_X,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6b8ac3e4-65ad-459a-8efb-22acc8d1fea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11276, 18), (11276,), (2819, 18), (2819,))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_train_X =   train_X.loc[:,test_stage_features]\n",
    "student_val_X = val_X.loc[:,test_stage_features]\n",
    "student_train_X.shape, train_y.shape, student_val_X.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ca9964b9-2b15-4613-86bb-96dfdd9a6592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "353/353 [==============================] - 2s 4ms/step - loss: 0.6796 - acc: 0.6967 - val_loss: 0.6537 - val_acc: 0.8099\n",
      "Epoch 2/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.5355 - acc: 0.8042 - val_loss: 0.4861 - val_acc: 0.8883\n",
      "Epoch 3/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.4442 - acc: 0.8905 - val_loss: 0.4170 - val_acc: 0.9071\n",
      "Epoch 4/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.3884 - acc: 0.9112 - val_loss: 0.3751 - val_acc: 0.9092\n",
      "Epoch 5/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.3521 - acc: 0.9138 - val_loss: 0.3408 - val_acc: 0.9131\n",
      "Epoch 6/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.3273 - acc: 0.9147 - val_loss: 0.3300 - val_acc: 0.9095\n",
      "Epoch 7/100\n",
      "353/353 [==============================] - 2s 5ms/step - loss: 0.3109 - acc: 0.9147 - val_loss: 0.3123 - val_acc: 0.9131\n",
      "Epoch 8/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.2997 - acc: 0.9147 - val_loss: 0.3007 - val_acc: 0.9127\n",
      "Epoch 9/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.2910 - acc: 0.9147 - val_loss: 0.2967 - val_acc: 0.9127\n",
      "Epoch 10/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.2859 - acc: 0.9147 - val_loss: 0.2945 - val_acc: 0.9110\n",
      "Epoch 11/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.2827 - acc: 0.9147 - val_loss: 0.2912 - val_acc: 0.9131\n",
      "Epoch 12/100\n",
      "353/353 [==============================] - 2s 5ms/step - loss: 0.2802 - acc: 0.9147 - val_loss: 0.2903 - val_acc: 0.9120\n",
      "Epoch 13/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.2783 - acc: 0.9147 - val_loss: 0.2878 - val_acc: 0.9124\n",
      "Epoch 14/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.2774 - acc: 0.9147 - val_loss: 0.2850 - val_acc: 0.9127\n",
      "Epoch 15/100\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.2749 - acc: 0.9147 - val_loss: 0.2921 - val_acc: 0.9120\n",
      "Epoch 16/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.2762 - acc: 0.9147 - val_loss: 0.2848 - val_acc: 0.9131\n",
      "Epoch 17/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.2749 - acc: 0.9148 - val_loss: 0.2837 - val_acc: 0.9138\n",
      "Epoch 18/100\n",
      "353/353 [==============================] - 2s 5ms/step - loss: 0.2751 - acc: 0.9149 - val_loss: 0.2837 - val_acc: 0.9131\n",
      "Epoch 19/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.2747 - acc: 0.9147 - val_loss: 0.2838 - val_acc: 0.9131\n",
      "Epoch 20/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.2746 - acc: 0.9148 - val_loss: 0.2857 - val_acc: 0.9134\n",
      "Epoch 21/100\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.2743 - acc: 0.9148 - val_loss: 0.2842 - val_acc: 0.9142\n",
      "Epoch 22/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.2742 - acc: 0.9147 - val_loss: 0.2814 - val_acc: 0.9138\n",
      "Epoch 23/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.2728 - acc: 0.9149 - val_loss: 0.2822 - val_acc: 0.9138\n",
      "Epoch 24/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.2741 - acc: 0.9147 - val_loss: 0.2841 - val_acc: 0.9142\n",
      "Epoch 25/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.2732 - acc: 0.9149 - val_loss: 0.2798 - val_acc: 0.9145\n",
      "Epoch 26/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.2730 - acc: 0.9147 - val_loss: 0.2842 - val_acc: 0.9131\n",
      "Epoch 27/100\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.2720 - acc: 0.9150 - val_loss: 0.2809 - val_acc: 0.9142\n",
      "Epoch 28/100\n",
      "353/353 [==============================] - 1s 4ms/step - loss: 0.2706 - acc: 0.9148 - val_loss: 0.2860 - val_acc: 0.9127\n",
      "Epoch 29/100\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.2721 - acc: 0.9150 - val_loss: 0.2841 - val_acc: 0.9124\n",
      "Epoch 30/100\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.2713 - acc: 0.9151 - val_loss: 0.2824 - val_acc: 0.9134\n",
      "Epoch 31/100\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.2719 - acc: 0.9150 - val_loss: 0.2816 - val_acc: 0.9138\n",
      "Epoch 32/100\n",
      "353/353 [==============================] - 1s 3ms/step - loss: 0.2716 - acc: 0.9152 - val_loss: 0.2814 - val_acc: 0.9142\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2798 - acc: 0.9145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.279834121465683, 0.9145087003707886]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학생모델 훈련\n",
    "student.compile(\n",
    "    optimizer=keras.optimizers.Adam()\n",
    "    ,loss = keras.losses.binary_crossentropy\n",
    "    ,metrics=['acc']\n",
    ")\n",
    "callback = [\n",
    "    keras.callbacks.EarlyStopping(patience = 7),\n",
    "    keras.callbacks.ModelCheckpoint('student.model.keras',save_best_only=True)\n",
    "]\n",
    "student.fit(student_train_X,train_y,epochs=100,callbacks=callback, validation_data=(student_val_X,val_y))\n",
    "student_loadmodel = keras.models.load_model('student.model.keras')\n",
    "student_loadmodel.evaluate(student_val_X,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "19f45703-952d-475d-aeca-37ce0758d6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.test(a=0, b=1)>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 일단 학생모델로 제출\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b4da9-0210-4b33-b3c0-bbf60a521c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b02fc68-d7f1-41b1-b283-109938519b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9744bae-f1ca-4bb7-bc37-3dd3dcd687c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6caf0d7f-1017-40de-9ce4-8c0fc229dc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "distillation_model = Distillation(student_loadmodel,teacher_loadmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "db3d7cf1-bba0-4a11-8005-070b2c51112d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "distillation_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "97426642-f19a-4d89-8a23-67b09b222798",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353/353 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "No gradient defined for operation'IteratorGetNext' (op type: IteratorGetNext). In general every operation must have an associated `@tf.RegisterGradient` for correct autodiff, which this op is lacking. If you want to pretend this operation is a constant in your program, you may insert `tf.stop_gradient`. This can be useful to silence the error in cases where you know gradients are not needed, e.g. the forward pass of tf.custom_gradient. Please see more details in https://www.tensorflow.org/api_docs/python/tf/custom_gradient.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [162]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdistillation_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstudent_train_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [159]\u001b[0m, in \u001b[0;36mDistillation.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# 자동미분\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# 학생의 전방 계산\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m     student_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstudent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# losses 계산\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     student_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudent_loss_fn(y, student_predictions)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:639\u001b[0m, in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    637\u001b[0m       grad_fn \u001b[38;5;241m=\u001b[39m func_call\u001b[38;5;241m.\u001b[39mpython_grad_func\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 639\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(\n\u001b[0;32m    640\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo gradient defined for operation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    641\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (op type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    642\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn general every operation must have an associated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    643\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`@tf.RegisterGradient` for correct autodiff, which this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    644\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mop is lacking. If you want to pretend this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    645\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moperation is a constant in your program, you may insert \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    646\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.stop_gradient`. This can be useful to silence the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    647\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror in cases where you know gradients are not needed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    648\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me.g. the forward pass of tf.custom_gradient. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    649\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see more details in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    650\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.tensorflow.org/api_docs/python/tf/custom_gradient.\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=line-too-long\u001b[39;00m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop_state:\n\u001b[0;32m    652\u001b[0m   loop_state\u001b[38;5;241m.\u001b[39mEnterGradWhileContext(op, before\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mLookupError\u001b[0m: No gradient defined for operation'IteratorGetNext' (op type: IteratorGetNext). In general every operation must have an associated `@tf.RegisterGradient` for correct autodiff, which this op is lacking. If you want to pretend this operation is a constant in your program, you may insert `tf.stop_gradient`. This can be useful to silence the error in cases where you know gradients are not needed, e.g. the forward pass of tf.custom_gradient. Please see more details in https://www.tensorflow.org/api_docs/python/tf/custom_gradient."
     ]
    }
   ],
   "source": [
    "distillation_model.train_step(\n",
    "    (train_X,student_train_X,train_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b645cc2-94d2-43e6-9233-a07336a45f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bb424a1a-ed8f-49ee-be7b-d49de449e1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353/353 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.05695007],\n",
       "       [0.04930936],\n",
       "       [0.04033683],\n",
       "       ...,\n",
       "       [0.06371115],\n",
       "       [0.05245271],\n",
       "       [0.05571058]], dtype=float32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_loadmodel.predict(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cb3216fc-33c1-46df-858d-236cc8fa0b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11276, 52), (11276,))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8317732b-b238-43b2-b8ef-dddf7d7f39a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Accuracy in module keras.metrics.metrics:\n",
      "\n",
      "class Accuracy(keras.metrics.base_metric.MeanMetricWrapper)\n",
      " |  Accuracy(name='accuracy', dtype=None)\n",
      " |  \n",
      " |  Calculates how often predictions equal labels.\n",
      " |  \n",
      " |  This metric creates two local variables, `total` and `count` that are used\n",
      " |  to compute the frequency with which `y_pred` matches `y_true`. This\n",
      " |  frequency is ultimately returned as `binary accuracy`: an idempotent\n",
      " |  operation that simply divides `total` by `count`.\n",
      " |  \n",
      " |  If `sample_weight` is `None`, weights default to 1.\n",
      " |  Use `sample_weight` of 0 to mask values.\n",
      " |  \n",
      " |  Args:\n",
      " |    name: (Optional) string name of the metric instance.\n",
      " |    dtype: (Optional) data type of the metric result.\n",
      " |  \n",
      " |  Standalone usage:\n",
      " |  \n",
      " |  >>> m = tf.keras.metrics.Accuracy()\n",
      " |  >>> m.update_state([[1], [2], [3], [4]], [[0], [2], [3], [4]])\n",
      " |  >>> m.result().numpy()\n",
      " |  0.75\n",
      " |  \n",
      " |  >>> m.reset_state()\n",
      " |  >>> m.update_state([[1], [2], [3], [4]], [[0], [2], [3], [4]],\n",
      " |  ...                sample_weight=[1, 1, 0, 0])\n",
      " |  >>> m.result().numpy()\n",
      " |  0.5\n",
      " |  \n",
      " |  Usage with `compile()` API:\n",
      " |  \n",
      " |  ```python\n",
      " |  model.compile(optimizer='sgd',\n",
      " |                loss='mse',\n",
      " |                metrics=[tf.keras.metrics.Accuracy()])\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Accuracy\n",
      " |      keras.metrics.base_metric.MeanMetricWrapper\n",
      " |      keras.metrics.base_metric.Mean\n",
      " |      keras.metrics.base_metric.Reduce\n",
      " |      keras.metrics.base_metric.Metric\n",
      " |      keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
      " |      tensorflow.python.trackable.base.Trackable\n",
      " |      keras.utils.version_utils.LayerVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, name='accuracy', dtype=None)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.metrics.base_metric.MeanMetricWrapper:\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the serializable config of the metric.\n",
      " |  \n",
      " |  update_state(self, y_true, y_pred, sample_weight=None)\n",
      " |      Accumulates metric statistics.\n",
      " |      \n",
      " |      For sparse categorical metrics, the shapes of `y_true` and `y_pred` are\n",
      " |      different.\n",
      " |      \n",
      " |      Args:\n",
      " |        y_true: Ground truth label values. shape = `[batch_size, d0, .. dN-1]` or\n",
      " |          shape = `[batch_size, d0, .. dN-1, 1]`.\n",
      " |        y_pred: The predicted probability values. shape = `[batch_size, d0, .. dN]`.\n",
      " |        sample_weight: Optional `sample_weight` acts as a\n",
      " |          coefficient for the metric. If a scalar is provided, then the metric is\n",
      " |          simply scaled by the given value. If `sample_weight` is a tensor of size\n",
      " |          `[batch_size]`, then the metric for each sample of the batch is rescaled\n",
      " |          by the corresponding element in the `sample_weight` vector. If the shape\n",
      " |          of `sample_weight` is `[batch_size, d0, .. dN-1]` (or can be broadcasted\n",
      " |          to this shape), then each metric element of `y_pred` is scaled by the\n",
      " |          corresponding value of `sample_weight`. (Note on `dN-1`: all metric\n",
      " |          functions reduce by 1 dimension, usually the last axis (-1)).\n",
      " |      \n",
      " |      Returns:\n",
      " |        Update op.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.metrics.base_metric.MeanMetricWrapper:\n",
      " |  \n",
      " |  from_config(config) from abc.ABCMeta\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.metrics.base_metric.Reduce:\n",
      " |  \n",
      " |  result(self)\n",
      " |      Computes and returns the scalar metric value tensor or a dict of\n",
      " |      scalars.\n",
      " |      \n",
      " |      Result computation is an idempotent operation that simply calculates the\n",
      " |      metric value using the state variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A scalar tensor, or a dictionary of scalar tensors.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.metrics.base_metric.Metric:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Accumulates statistics and then computes metric result value.\n",
      " |      \n",
      " |      Args:\n",
      " |        *args:\n",
      " |        **kwargs: A mini-batch of inputs to the Metric,\n",
      " |          passed on to `update_state()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The metric value tensor.\n",
      " |  \n",
      " |  __deepcopy__(self, memo)\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  add_weight(self, name, shape=(), aggregation=<VariableAggregationV2.SUM: 1>, synchronization=<VariableSynchronization.ON_READ: 3>, initializer=None, dtype=None)\n",
      " |      Adds state variable. Only for use by subclasses.\n",
      " |  \n",
      " |  merge_state(self, metrics)\n",
      " |      Merges the state from one or more metrics.\n",
      " |      \n",
      " |      This method can be used by distributed systems to merge the state\n",
      " |      computed by different metric instances. Typically the state will be\n",
      " |      stored in the form of the metric's weights. For example, a\n",
      " |      tf.keras.metrics.Mean metric contains a list of two weight values: a\n",
      " |      total and a count. If there were two instances of a\n",
      " |      tf.keras.metrics.Accuracy that each independently aggregated partial\n",
      " |      state for an overall accuracy calculation, these two metric's states\n",
      " |      could be combined as follows:\n",
      " |      \n",
      " |      >>> m1 = tf.keras.metrics.Accuracy()\n",
      " |      >>> _ = m1.update_state([[1], [2]], [[0], [2]])\n",
      " |      \n",
      " |      >>> m2 = tf.keras.metrics.Accuracy()\n",
      " |      >>> _ = m2.update_state([[3], [4]], [[3], [4]])\n",
      " |      \n",
      " |      >>> m2.merge_state([m1])\n",
      " |      >>> m2.result().numpy()\n",
      " |      0.75\n",
      " |      \n",
      " |      Args:\n",
      " |        metrics: an iterable of metrics. The metrics must have compatible\n",
      " |          state.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the provided iterable does not contain metrics matching\n",
      " |          the metric's required specifications.\n",
      " |  \n",
      " |  reset_state(self)\n",
      " |      Resets all of the metric state variables.\n",
      " |      \n",
      " |      This function is called between epochs/steps,\n",
      " |      when a metric is evaluated during training.\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from keras.metrics.base_metric.Metric:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.metrics.base_metric.Metric:\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are\n",
      " |      expected to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be\n",
      " |      dependent on the inputs passed when calling a layer. Hence, when reusing\n",
      " |      the same layer on different inputs `a` and `b`, some entries in\n",
      " |      `layer.losses` may be dependent on `a` and some on `b`. This method\n",
      " |      automatically keeps track of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in\n",
      " |      `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss\n",
      " |      references a `Variable` of one of the model's layers), you can wrap your\n",
      " |      loss in a zero-argument lambda. These losses are not tracked as part of\n",
      " |      the model's topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors,\n",
      " |          losses may also be zero-argument callables which create a loss\n",
      " |          tensor.\n",
      " |        **kwargs: Used for backwards compatibility only.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(inputs))\n",
      " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This\n",
      " |      is because we cannot trace the metric result tensor back to the model's\n",
      " |      inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result\n",
      " |          of calling a `keras.Metric` instance, it will be aggregated by\n",
      " |          default using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and\n",
      " |      variance in a BatchNormalization layer) may be dependent on the inputs\n",
      " |      passed when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case,\n",
      " |      variable updates are run on the fly and thus do not need to be tracked\n",
      " |      for later execution).\n",
      " |      \n",
      " |      Args:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call. It is invoked automatically before\n",
      " |      the first execution of `call()`.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses\n",
      " |      (at the discretion of the subclass implementer).\n",
      " |      \n",
      " |      Args:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  call(self, inputs, *args, **kwargs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      The `call()` method may not create state (except in its first\n",
      " |      invocation, wrapping the creation of variables or other resources in\n",
      " |      `tf.init_scope()`).  It is recommended to create state in `__init__()`,\n",
      " |      or the `build()` method that is called automatically before `call()`\n",
      " |      executes the first time.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor, or dict/list/tuple of input tensors.\n",
      " |          The first positional `inputs` argument is subject to special rules:\n",
      " |          - `inputs` must be explicitly passed. A layer cannot have zero\n",
      " |            arguments, and `inputs` cannot be provided via the default value\n",
      " |            of a keyword argument.\n",
      " |          - NumPy array or Python scalar values in `inputs` get cast as\n",
      " |            tensors.\n",
      " |          - Keras mask metadata is only collected from `inputs`.\n",
      " |          - Layers are built (`build(input_shape)` method)\n",
      " |            using shape info from `inputs` only.\n",
      " |          - `input_spec` compatibility is only checked against `inputs`.\n",
      " |          - Mixed precision input casting is only applied to `inputs`.\n",
      " |            If a layer has tensor arguments in `*args` or `**kwargs`, their\n",
      " |            casting behavior in mixed precision should be handled manually.\n",
      " |          - The SavedModel input specification is generated using `inputs`\n",
      " |            only.\n",
      " |          - Integration with various ecosystem packages like TFMOT, TFLite,\n",
      " |            TF.js, etc is only supported for `inputs` and not for tensors in\n",
      " |            positional and keyword arguments.\n",
      " |        *args: Additional positional arguments. May contain tensors, although\n",
      " |          this is not recommended, for the reasons above.\n",
      " |        **kwargs: Additional keyword arguments. May contain tensors, although\n",
      " |          this is not recommended, for the reasons above.\n",
      " |          The following optional keyword arguments are reserved:\n",
      " |          - `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          - `mask`: Boolean input mask. If the layer's `call()` method takes a\n",
      " |            `mask` argument, its default value will be set to the mask\n",
      " |            generated for `inputs` by the previous layer (if `input` did come\n",
      " |            from a layer that generated a corresponding mask, i.e. if it came\n",
      " |            from a Keras layer with masking support).\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      This method will cause the layer's state to be built, if that has not\n",
      " |      happened before. This requires that the layer will later be used with\n",
      " |      inputs that match the input shape provided here.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects,\n",
      " |          describing how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  finalize_state(self)\n",
      " |      Finalizes the layers state after updating layer weights.\n",
      " |      \n",
      " |      This function can be subclassed in a layer and will be called after\n",
      " |      updating a layer weights. It can be overridden to finalize any\n",
      " |      additional layer state after a weight update.\n",
      " |      \n",
      " |      This function will be called after weights of a layer have been restored\n",
      " |      from a loaded model.\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first input node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first output node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer, as NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      returns both trainable and non-trainable weight values associated with\n",
      " |      this layer as a list of NumPy arrays, which can in turn be used to load\n",
      " |      state into similarly parameterized layers.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel\n",
      " |      matrix and the bias vector. These can be used to set the weights of\n",
      " |      another `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of NumPy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function, by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel\n",
      " |      matrix and the bias vector. These can be used to set the weights of\n",
      " |      another `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a list of NumPy arrays. The number\n",
      " |          of arrays and their shape must match\n",
      " |          number of the dimensions of the weights\n",
      " |          of the layer (i.e. it should match the\n",
      " |          output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the provided weights list does not match the\n",
      " |          layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which\n",
      " |      causes computations and the output to be in the compute dtype as well.\n",
      " |      This is done by the base Layer class in `Layer.__call__`, so you do not\n",
      " |      have to insert these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision\n",
      " |      when `compute_dtype` is float16 or bfloat16 for numeric stability. The\n",
      " |      output will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Return Functional API nodes upstream of this layer.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is\n",
      " |      accessed, so it is eager safe: accessing `losses` under a\n",
      " |      `tf.GradientTape` will propagate gradients back to the corresponding\n",
      " |      variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |      List of metrics added using the `add_metric()` API.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      >>> input = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2)\n",
      " |      >>> output = d(input)\n",
      " |      >>> d.add_metric(tf.reduce_max(output), name='max')\n",
      " |      >>> d.add_metric(tf.reduce_min(output), name='min')\n",
      " |      >>> [m.name for m in d.metrics]\n",
      " |      ['max', 'min']\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of `Metric` objects.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Return Functional API nodes downstream of this layer.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are\n",
      " |      not themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to\n",
      " |      enable the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input\n",
      " |      tensor of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a\n",
      " |      nicely-formatted error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from abc.ABCMeta\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.keras.metrics.Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c8dda6-047d-46cd-a54a-a361f0f2c8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer, metrics, student_loss_fn, distillation_loss_fn\n",
    "\n",
    "# Distillation_model.compile("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "baab59be-4e56-4c09-be23-031a4ec4b8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sparse_categorical_crossentropy in module keras.losses:\n",
      "\n",
      "sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1, ignore_class=None)\n",
      "    Computes the sparse categorical crossentropy loss.\n",
      "    \n",
      "    Standalone usage:\n",
      "    \n",
      "    >>> y_true = [1, 2]\n",
      "    >>> y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
      "    >>> loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
      "    >>> assert loss.shape == (2,)\n",
      "    >>> loss.numpy()\n",
      "    array([0.0513, 2.303], dtype=float32)\n",
      "    \n",
      "    >>> y_true = [[[ 0,  2],\n",
      "    ...            [-1, -1]],\n",
      "    ...           [[ 0,  2],\n",
      "    ...            [-1, -1]]]\n",
      "    >>> y_pred = [[[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0]],\n",
      "    ...             [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]],\n",
      "    ...           [[[1.0, 0.0, 0.0], [0.0, 0.5, 0.5]],\n",
      "    ...            [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]]]\n",
      "    >>> loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
      "    ...   y_true, y_pred, ignore_class=-1)\n",
      "    >>> loss.numpy()\n",
      "    array([[[2.3841855e-07, 2.3841855e-07],\n",
      "            [0.0000000e+00, 0.0000000e+00]],\n",
      "           [[2.3841855e-07, 6.9314730e-01],\n",
      "            [0.0000000e+00, 0.0000000e+00]]], dtype=float32)\n",
      "    \n",
      "    Args:\n",
      "      y_true: Ground truth values.\n",
      "      y_pred: The predicted values.\n",
      "      from_logits: Whether `y_pred` is expected to be a logits tensor. By\n",
      "        default, we assume that `y_pred` encodes a probability distribution.\n",
      "      axis: Defaults to -1. The dimension along which the entropy is\n",
      "        computed.\n",
      "      ignore_class: Optional integer. The ID of a class to be ignored during\n",
      "        loss computation. This is useful, for example, in segmentation\n",
      "        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n",
      "        maps. By default (`ignore_class=None`), all classes are considered.\n",
      "    \n",
      "    Returns:\n",
      "      Sparse categorical crossentropy loss value.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.keras.losses.sparse_categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e307bc37-6ea8-486c-b884-fee82cc230cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
