{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33658531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝을 이용한 자연어처리\n",
    "# 1. 데이터 준비\n",
    "# 2. 텍스트를 표준화\n",
    "# 3. 텍스트 분할(토큰화)\n",
    "# 4. 어휘 인덱싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0671d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45816d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"I write, rewrite, and still rewrite again!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "449e8f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i write, rewrite, and still rewrite again!!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = test_sentence.lower()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "402d2f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i write rewrite and still rewrite again'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2edff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 표준화 함수\n",
    "def standardize(text):\n",
    "    text = text.lower()\n",
    "    return \"\".join([char for char in text if char not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77067ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화\n",
    "def tokenize(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e781d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary 화\n",
    "vocabulary = {\"\":0, \"[UNK]\":1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e3cdd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    \"I write, erase, rewrite\",\n",
    "    \"Erase again, and then\",\n",
    "    \"A poppy blooms.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75133244",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in dataset:\n",
    "    text = standardize(text)\n",
    "    tokens = tokenize(text)\n",
    "    for token in tokens:\n",
    "        if token not in vocabulary:\n",
    "            vocabulary[token] = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4556cf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " '[UNK]': 1,\n",
       " 'i': 2,\n",
       " 'write': 3,\n",
       " 'erase': 4,\n",
       " 'rewrite': 5,\n",
       " 'again': 6,\n",
       " 'and': 7,\n",
       " 'then': 8,\n",
       " 'a': 9,\n",
       " 'poppy': 10,\n",
       " 'blooms': 11}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict((k,v) for k, v in vocabulary.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6127909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " '[UNK]': 1,\n",
       " 'i': 2,\n",
       " 'write': 3,\n",
       " 'erase': 4,\n",
       " 'rewrite': 5,\n",
       " 'again': 6,\n",
       " 'and': 7,\n",
       " 'then': 8,\n",
       " 'a': 9,\n",
       " 'poppy': 10,\n",
       " 'blooms': 11}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96b73178",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorizer:\n",
    "    def standardize(self, text):\n",
    "        text = text.lower()\n",
    "        return \"\".join(char for char in text if char not in string.punctuation)\n",
    "    def tokenize(self, text):\n",
    "        return text.split()\n",
    "    def make_vocabulary(self, dataset):\n",
    "        self.vocabulary = {\"\":0, '[UNK]' : 1}\n",
    "        for text in dataset:\n",
    "            text = self.standardize(text)\n",
    "            tokens = self.tokenize(text)\n",
    "            for token in tokens:\n",
    "                if token not in self.vocabulary:\n",
    "                    self.vocabulary[token] = len(self.vocabulary)\n",
    "        self.inverse_vocabulary = dict(\n",
    "            (v,k) for k, v in self.vocabulary.items()\n",
    "        )\n",
    "    def encode(self,text):\n",
    "        text = self.standardize(text)\n",
    "        tokens = self.tokenize(text)\n",
    "        return [self.vocabulary.get(token,1) for token in tokens]\n",
    "    def decode(self, int_sequence):\n",
    "        return \" \".join(\n",
    "            self.inverse_vocabulary.get(i,'[UNK]') for i in int_sequence\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73d2af99",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer()\n",
    "dataset = [\n",
    "    'I write, erase, rewrite',\n",
    "    'Erase again, and then',\n",
    "    'A poppy blooms'\n",
    "]\n",
    "vectorizer.make_vocabulary(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d59ef6f-b584-4595-8ad7-2603aee1755a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " '[UNK]': 1,\n",
       " 'i': 2,\n",
       " 'write': 3,\n",
       " 'erase': 4,\n",
       " 'rewrite': 5,\n",
       " 'again': 6,\n",
       " 'and': 7,\n",
       " 'then': 8,\n",
       " 'a': 9,\n",
       " 'poppy': 10,\n",
       " 'blooms': 11}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 집합에 없는 단어일 경우 UNK로 대체\n",
    "vectorizer.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56b1d0e5-fca2-454d-bdf1-8b31bb2a8d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 7, 1, 5, 6]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = \"I write, erase, rewrite and still rewrite again\"\n",
    "encoded_sentence = vectorizer.encode(test_sentence)\n",
    "encoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46525ba3-0156-4247-a2f5-1aa1c802c646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '',\n",
       " 1: '[UNK]',\n",
       " 2: 'i',\n",
       " 3: 'write',\n",
       " 4: 'erase',\n",
       " 5: 'rewrite',\n",
       " 6: 'again',\n",
       " 7: 'and',\n",
       " 8: 'then',\n",
       " 9: 'a',\n",
       " 10: 'poppy',\n",
       " 11: 'blooms'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.inverse_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81306888-8886-469c-b631-78466e9f221c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i write erase rewrite and [UNK] rewrite again'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sentence = vectorizer.decode(encoded_sentence)\n",
    "decode_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb4354f0-2611-4445-a7d2-3e11a1207f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "text_vectorization = TextVectorization(output_mode='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5fe8962-93dc-4d31-a7f9-b866a65232e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "def custom_standardization_fn(string_tensor):\n",
    "    lowercase_string =  tf.strings.lower(string_tensor)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase_string, f\"[{re.escape(string.punctuation)}]\",\"\"\n",
    "    )\n",
    "def custom_split_fn(string_tensor):\n",
    "    return tf.strings.split(string_tensor)\n",
    "\n",
    "text_vectorization = TextVectorization(\n",
    "    output_mode='int',\n",
    "    standardize=custom_standardization_fn,\n",
    "    split=custom_split_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c41d89cf-731c-4e59-9cfb-f990dca4c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    'I write, erase, rewrite',\n",
    "    'Erase again, and then',\n",
    "    'A poppy blooms'\n",
    "]\n",
    "text_vectorization.adapt(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98adf94b-db7e-45ec-b445-f1a8501fb004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'erase',\n",
       " 'write',\n",
       " 'then',\n",
       " 'rewrite',\n",
       " 'poppy',\n",
       " 'i',\n",
       " 'blooms',\n",
       " 'and',\n",
       " 'again',\n",
       " 'a']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어휘 사전 출력\n",
    "text_vectorization.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "873a7e1a-4f53-4d0b-a533-48bda147b4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=int64, numpy=array([ 7,  3,  5,  9,  1,  5, 10], dtype=int64)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = text_vectorization.get_vocabulary()\n",
    "test_sentence = \"I write, rewrite, and still rewrite again\"\n",
    "encode_sentence = text_vectorization(test_sentence)\n",
    "encode_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50f56593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i write rewrite and [UNK] rewrite again'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_vocab = dict(enumerate(vocabulary))\n",
    "decode_sentence = \" \".join(inverse_vocab[int(i)] for i in encode_sentence)\n",
    "decode_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "252c9031-b23c-4e98-921c-3983229b2b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 그룹을 표현하는 두 가지 방법: 집합과 시퀀스\n",
    "# IMDB 영화 리뷰 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed694209-f69b-4a0b-8011-96adc028f82b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
