{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b07019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbfb2e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "little_star=\"tinynotation: 4/4 c4 c4 g4 g4 a4 a4 g2 f4 f4 e4 e4 d4 d4 c2 g4 g4 f4 f4 e4 e4 d2 g4 g4 f4 f4 e4 e4 d2 c4 c4 g4 g4 a4 a4 g2 f4 f4 e4 e4 d4 d4 c2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b78025c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "music21.converter.parse(little_star).show('mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c851f0",
   "metadata": {},
   "source": [
    "#### 계이름과 숫자를  상호 변환하는 표 - dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f517ecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = [1,2,3,4,5,6,7]\n",
    "temp2 = ['c','d','e','f','g','a','b']\n",
    "note2num = {}\n",
    "for key,value in zip(temp2,temp1):\n",
    "    note2num[key] = value\n",
    "num2note = {}\n",
    "for key,value in zip(temp1,temp2):\n",
    "    num2note[key] = value  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b7d8f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c': 1, 'd': 2, 'e': 3, 'f': 4, 'g': 5, 'a': 6, 'b': 7}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note2num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bbf04e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'c', 2: 'd', 3: 'e', 4: 'f', 5: 'g', 6: 'a', 7: 'b'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num2note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bf1dea",
   "metadata": {},
   "source": [
    "#### ABC 표기를 시계열 데이터로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8ba9b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abc2timeseries(s):\n",
    "    notes = s.split(' ')[2:]\n",
    "    seq = []\n",
    "    for i in notes:\n",
    "        seq.append([note2num[i[0]], int(i[1])])\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fce058f",
   "metadata": {},
   "source": [
    "#### 시계열 데이터를 ABC 표기로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3e155ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries2abc(t):\n",
    "    s = 'tinynotation: 4/4'\n",
    "    for i in t:\n",
    "        s = s+' '+num2note[i[0]]+str(i[1])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4deea9",
   "metadata": {},
   "source": [
    "#### 원핫 코드로 변환하는 표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad5d689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2음절,4음절,8음절\n",
    "onehot = [[i,2] for i in range(1,8)] +[[i,4] for i in range(1,8)]+[[i,8] for i in range(1,8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd19f306",
   "metadata": {},
   "source": [
    "#### 레이블을 원핫 코드로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1b8f36cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def to_onehot(la):\n",
    "    t = []\n",
    "    for i in range(len(la)):\n",
    "        a = np.zeros(len(onehot))\n",
    "        a[onehot.index(list(la[i]))] = 1.0\n",
    "        t.append(a)\n",
    "    return np.array(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504505e3",
   "metadata": {},
   "source": [
    "#### 시계열 데이터를 훈련 집합으로 자름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9158ee22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2dataset(seq,window,horizon):\n",
    "    X,Y = [],[]\n",
    "    for i in range(len(seq) - (window+horizon)+1):\n",
    "        x = seq[i:(i+window)]\n",
    "        y = (seq[i+window+horizon-1])\n",
    "        X.append(x); Y.append(y)\n",
    "    return np.array(X,dtype=object), np.array(Y,dtype=object) # 경고메세지에따라서 dtype=object 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8a3a483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 윈도우크기, 수평선 계수\n",
    "w=8; h=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e91bd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tinynotation: 4/4 c4 c4 g4 g4 a4 a4 g2 f4 f4 e4 e4 d4 d4 c2 g4 g4 f4 f4 e4 e4 d2 g4 g4 f4 f4 e4 e4 d2 c4 c4 g4 g4 a4 a4 g2 f4 f4 e4 e4 d4 d4 c2'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "little_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b6da2bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 8, 2) (34, 2)\n",
      "[[1 4]\n",
      " [1 4]\n",
      " [5 4]\n",
      " [5 4]\n",
      " [6 4]\n",
      " [6 4]\n",
      " [5 2]\n",
      " [4 4]] [4 4]\n"
     ]
    }
   ],
   "source": [
    "seq = abc2timeseries( little_star)\n",
    "X,Y = seq2dataset(seq,w,h)\n",
    "print(X.shape, Y.shape)\n",
    "print(X[0], Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4938f1e7",
   "metadata": {},
   "source": [
    "#### 훈련집합 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e3512b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(X)*1.0)  # 100%를 훈련 집합으로 사용\n",
    "x_train = X[:split]; y_train = Y[:split]\n",
    "y_train = to_onehot(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e68865",
   "metadata": {},
   "source": [
    "#### LSTM 모델 설계와 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2b568aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "import tensorflow as  tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1de62d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 - 1s - loss: 2.5809 - accuracy: 0.1765 - 896ms/epoch - 26ms/step\n",
      "Epoch 2/200\n",
      "34/34 - 0s - loss: 2.2092 - accuracy: 0.2059 - 70ms/epoch - 2ms/step\n",
      "Epoch 3/200\n",
      "34/34 - 0s - loss: 2.0449 - accuracy: 0.2059 - 84ms/epoch - 2ms/step\n",
      "Epoch 4/200\n",
      "34/34 - 0s - loss: 1.8823 - accuracy: 0.2647 - 77ms/epoch - 2ms/step\n",
      "Epoch 5/200\n",
      "34/34 - 0s - loss: 1.7716 - accuracy: 0.3235 - 70ms/epoch - 2ms/step\n",
      "Epoch 6/200\n",
      "34/34 - 0s - loss: 1.5632 - accuracy: 0.4118 - 80ms/epoch - 2ms/step\n",
      "Epoch 7/200\n",
      "34/34 - 0s - loss: 1.6570 - accuracy: 0.4412 - 85ms/epoch - 3ms/step\n",
      "Epoch 8/200\n",
      "34/34 - 0s - loss: 1.4523 - accuracy: 0.5294 - 76ms/epoch - 2ms/step\n",
      "Epoch 9/200\n",
      "34/34 - 0s - loss: 1.5017 - accuracy: 0.5588 - 80ms/epoch - 2ms/step\n",
      "Epoch 10/200\n",
      "34/34 - 0s - loss: 1.3921 - accuracy: 0.4706 - 92ms/epoch - 3ms/step\n",
      "Epoch 11/200\n",
      "34/34 - 0s - loss: 1.4224 - accuracy: 0.3529 - 99ms/epoch - 3ms/step\n",
      "Epoch 12/200\n",
      "34/34 - 0s - loss: 1.2358 - accuracy: 0.5588 - 100ms/epoch - 3ms/step\n",
      "Epoch 13/200\n",
      "34/34 - 0s - loss: 1.1800 - accuracy: 0.5588 - 105ms/epoch - 3ms/step\n",
      "Epoch 14/200\n",
      "34/34 - 0s - loss: 1.2336 - accuracy: 0.5294 - 100ms/epoch - 3ms/step\n",
      "Epoch 15/200\n",
      "34/34 - 0s - loss: 1.0860 - accuracy: 0.5000 - 80ms/epoch - 2ms/step\n",
      "Epoch 16/200\n",
      "34/34 - 0s - loss: 0.9153 - accuracy: 0.6176 - 77ms/epoch - 2ms/step\n",
      "Epoch 17/200\n",
      "34/34 - 0s - loss: 1.0632 - accuracy: 0.6176 - 78ms/epoch - 2ms/step\n",
      "Epoch 18/200\n",
      "34/34 - 0s - loss: 0.9331 - accuracy: 0.6471 - 89ms/epoch - 3ms/step\n",
      "Epoch 19/200\n",
      "34/34 - 0s - loss: 0.8666 - accuracy: 0.6176 - 89ms/epoch - 3ms/step\n",
      "Epoch 20/200\n",
      "34/34 - 0s - loss: 0.8394 - accuracy: 0.6765 - 86ms/epoch - 3ms/step\n",
      "Epoch 21/200\n",
      "34/34 - 0s - loss: 1.0385 - accuracy: 0.5588 - 102ms/epoch - 3ms/step\n",
      "Epoch 22/200\n",
      "34/34 - 0s - loss: 0.8838 - accuracy: 0.6471 - 100ms/epoch - 3ms/step\n",
      "Epoch 23/200\n",
      "34/34 - 0s - loss: 0.7998 - accuracy: 0.6471 - 91ms/epoch - 3ms/step\n",
      "Epoch 24/200\n",
      "34/34 - 0s - loss: 0.6117 - accuracy: 0.7353 - 95ms/epoch - 3ms/step\n",
      "Epoch 25/200\n",
      "34/34 - 0s - loss: 1.1014 - accuracy: 0.6765 - 94ms/epoch - 3ms/step\n",
      "Epoch 26/200\n",
      "34/34 - 0s - loss: 1.0986 - accuracy: 0.5882 - 91ms/epoch - 3ms/step\n",
      "Epoch 27/200\n",
      "34/34 - 0s - loss: 0.6891 - accuracy: 0.7353 - 83ms/epoch - 2ms/step\n",
      "Epoch 28/200\n",
      "34/34 - 0s - loss: 0.6807 - accuracy: 0.7353 - 69ms/epoch - 2ms/step\n",
      "Epoch 29/200\n",
      "34/34 - 0s - loss: 0.6486 - accuracy: 0.7059 - 76ms/epoch - 2ms/step\n",
      "Epoch 30/200\n",
      "34/34 - 0s - loss: 0.4797 - accuracy: 0.7647 - 95ms/epoch - 3ms/step\n",
      "Epoch 31/200\n",
      "34/34 - 0s - loss: 0.5771 - accuracy: 0.7647 - 90ms/epoch - 3ms/step\n",
      "Epoch 32/200\n",
      "34/34 - 0s - loss: 0.6132 - accuracy: 0.7647 - 96ms/epoch - 3ms/step\n",
      "Epoch 33/200\n",
      "34/34 - 0s - loss: 0.4974 - accuracy: 0.8235 - 89ms/epoch - 3ms/step\n",
      "Epoch 34/200\n",
      "34/34 - 0s - loss: 0.4938 - accuracy: 0.7353 - 79ms/epoch - 2ms/step\n",
      "Epoch 35/200\n",
      "34/34 - 0s - loss: 0.6838 - accuracy: 0.7353 - 66ms/epoch - 2ms/step\n",
      "Epoch 36/200\n",
      "34/34 - 0s - loss: 0.6192 - accuracy: 0.7353 - 72ms/epoch - 2ms/step\n",
      "Epoch 37/200\n",
      "34/34 - 0s - loss: 0.5774 - accuracy: 0.7941 - 84ms/epoch - 2ms/step\n",
      "Epoch 38/200\n",
      "34/34 - 0s - loss: 0.3522 - accuracy: 0.8529 - 98ms/epoch - 3ms/step\n",
      "Epoch 39/200\n",
      "34/34 - 0s - loss: 0.4659 - accuracy: 0.8235 - 99ms/epoch - 3ms/step\n",
      "Epoch 40/200\n",
      "34/34 - 0s - loss: 0.3557 - accuracy: 0.8235 - 96ms/epoch - 3ms/step\n",
      "Epoch 41/200\n",
      "34/34 - 0s - loss: 0.2782 - accuracy: 0.9412 - 88ms/epoch - 3ms/step\n",
      "Epoch 42/200\n",
      "34/34 - 0s - loss: 0.2146 - accuracy: 0.9118 - 113ms/epoch - 3ms/step\n",
      "Epoch 43/200\n",
      "34/34 - 0s - loss: 0.3928 - accuracy: 0.8235 - 102ms/epoch - 3ms/step\n",
      "Epoch 44/200\n",
      "34/34 - 0s - loss: 0.5160 - accuracy: 0.7941 - 94ms/epoch - 3ms/step\n",
      "Epoch 45/200\n",
      "34/34 - 0s - loss: 0.3346 - accuracy: 0.8824 - 96ms/epoch - 3ms/step\n",
      "Epoch 46/200\n",
      "34/34 - 0s - loss: 0.2572 - accuracy: 0.8824 - 91ms/epoch - 3ms/step\n",
      "Epoch 47/200\n",
      "34/34 - 0s - loss: 0.2360 - accuracy: 0.9118 - 91ms/epoch - 3ms/step\n",
      "Epoch 48/200\n",
      "34/34 - 0s - loss: 0.2125 - accuracy: 0.8824 - 89ms/epoch - 3ms/step\n",
      "Epoch 49/200\n",
      "34/34 - 0s - loss: 0.2983 - accuracy: 0.8824 - 97ms/epoch - 3ms/step\n",
      "Epoch 50/200\n",
      "34/34 - 0s - loss: 0.3767 - accuracy: 0.8824 - 101ms/epoch - 3ms/step\n",
      "Epoch 51/200\n",
      "34/34 - 0s - loss: 0.3082 - accuracy: 0.8529 - 95ms/epoch - 3ms/step\n",
      "Epoch 52/200\n",
      "34/34 - 0s - loss: 0.3961 - accuracy: 0.7941 - 97ms/epoch - 3ms/step\n",
      "Epoch 53/200\n",
      "34/34 - 0s - loss: 1.3185 - accuracy: 0.7059 - 98ms/epoch - 3ms/step\n",
      "Epoch 54/200\n",
      "34/34 - 0s - loss: 0.7686 - accuracy: 0.7941 - 86ms/epoch - 3ms/step\n",
      "Epoch 55/200\n",
      "34/34 - 0s - loss: 0.2243 - accuracy: 0.9412 - 70ms/epoch - 2ms/step\n",
      "Epoch 56/200\n",
      "34/34 - 0s - loss: 0.1616 - accuracy: 0.9118 - 71ms/epoch - 2ms/step\n",
      "Epoch 57/200\n",
      "34/34 - 0s - loss: 0.2223 - accuracy: 0.9118 - 71ms/epoch - 2ms/step\n",
      "Epoch 58/200\n",
      "34/34 - 0s - loss: 0.8809 - accuracy: 0.6471 - 74ms/epoch - 2ms/step\n",
      "Epoch 59/200\n",
      "34/34 - 0s - loss: 0.5464 - accuracy: 0.7941 - 72ms/epoch - 2ms/step\n",
      "Epoch 60/200\n",
      "34/34 - 0s - loss: 0.2635 - accuracy: 0.8824 - 100ms/epoch - 3ms/step\n",
      "Epoch 61/200\n",
      "34/34 - 0s - loss: 0.1611 - accuracy: 0.9412 - 95ms/epoch - 3ms/step\n",
      "Epoch 62/200\n",
      "34/34 - 0s - loss: 0.1317 - accuracy: 0.9412 - 109ms/epoch - 3ms/step\n",
      "Epoch 63/200\n",
      "34/34 - 0s - loss: 0.0843 - accuracy: 0.9412 - 106ms/epoch - 3ms/step\n",
      "Epoch 64/200\n",
      "34/34 - 0s - loss: 0.0945 - accuracy: 0.9706 - 99ms/epoch - 3ms/step\n",
      "Epoch 65/200\n",
      "34/34 - 0s - loss: 0.0858 - accuracy: 0.9706 - 106ms/epoch - 3ms/step\n",
      "Epoch 66/200\n",
      "34/34 - 0s - loss: 0.1144 - accuracy: 0.9412 - 91ms/epoch - 3ms/step\n",
      "Epoch 67/200\n",
      "34/34 - 0s - loss: 0.0862 - accuracy: 0.9706 - 83ms/epoch - 2ms/step\n",
      "Epoch 68/200\n",
      "34/34 - 0s - loss: 0.0751 - accuracy: 0.9706 - 67ms/epoch - 2ms/step\n",
      "Epoch 69/200\n",
      "34/34 - 0s - loss: 0.1139 - accuracy: 0.9412 - 69ms/epoch - 2ms/step\n",
      "Epoch 70/200\n",
      "34/34 - 0s - loss: 0.2563 - accuracy: 0.9118 - 73ms/epoch - 2ms/step\n",
      "Epoch 71/200\n",
      "34/34 - 0s - loss: 0.2611 - accuracy: 0.9412 - 80ms/epoch - 2ms/step\n",
      "Epoch 72/200\n",
      "34/34 - 0s - loss: 0.1101 - accuracy: 0.9706 - 85ms/epoch - 2ms/step\n",
      "Epoch 73/200\n",
      "34/34 - 0s - loss: 0.1512 - accuracy: 0.9706 - 70ms/epoch - 2ms/step\n",
      "Epoch 74/200\n",
      "34/34 - 0s - loss: 0.4163 - accuracy: 0.8529 - 67ms/epoch - 2ms/step\n",
      "Epoch 75/200\n",
      "34/34 - 0s - loss: 0.1981 - accuracy: 0.9118 - 112ms/epoch - 3ms/step\n",
      "Epoch 76/200\n",
      "34/34 - 0s - loss: 0.0523 - accuracy: 0.9706 - 94ms/epoch - 3ms/step\n",
      "Epoch 77/200\n",
      "34/34 - 0s - loss: 0.0877 - accuracy: 0.9412 - 87ms/epoch - 3ms/step\n",
      "Epoch 78/200\n",
      "34/34 - 0s - loss: 0.0476 - accuracy: 1.0000 - 110ms/epoch - 3ms/step\n",
      "Epoch 79/200\n",
      "34/34 - 0s - loss: 0.0546 - accuracy: 1.0000 - 92ms/epoch - 3ms/step\n",
      "Epoch 80/200\n",
      "34/34 - 0s - loss: 0.0941 - accuracy: 0.9412 - 95ms/epoch - 3ms/step\n",
      "Epoch 81/200\n",
      "34/34 - 0s - loss: 0.0769 - accuracy: 0.9412 - 86ms/epoch - 3ms/step\n",
      "Epoch 82/200\n",
      "34/34 - 0s - loss: 0.0602 - accuracy: 0.9706 - 77ms/epoch - 2ms/step\n",
      "Epoch 83/200\n",
      "34/34 - 0s - loss: 0.0544 - accuracy: 0.9706 - 87ms/epoch - 3ms/step\n",
      "Epoch 84/200\n",
      "34/34 - 0s - loss: 0.1274 - accuracy: 0.9412 - 100ms/epoch - 3ms/step\n",
      "Epoch 85/200\n",
      "34/34 - 0s - loss: 0.0823 - accuracy: 0.9706 - 95ms/epoch - 3ms/step\n",
      "Epoch 86/200\n",
      "34/34 - 0s - loss: 0.0639 - accuracy: 0.9412 - 91ms/epoch - 3ms/step\n",
      "Epoch 87/200\n",
      "34/34 - 0s - loss: 0.0487 - accuracy: 0.9706 - 89ms/epoch - 3ms/step\n",
      "Epoch 88/200\n",
      "34/34 - 0s - loss: 0.0496 - accuracy: 0.9706 - 90ms/epoch - 3ms/step\n",
      "Epoch 89/200\n",
      "34/34 - 0s - loss: 0.0508 - accuracy: 0.9412 - 103ms/epoch - 3ms/step\n",
      "Epoch 90/200\n",
      "34/34 - 0s - loss: 0.0452 - accuracy: 0.9706 - 87ms/epoch - 3ms/step\n",
      "Epoch 91/200\n",
      "34/34 - 0s - loss: 0.0401 - accuracy: 0.9706 - 88ms/epoch - 3ms/step\n",
      "Epoch 92/200\n",
      "34/34 - 0s - loss: 0.0536 - accuracy: 0.9706 - 95ms/epoch - 3ms/step\n",
      "Epoch 93/200\n",
      "34/34 - 0s - loss: 0.1789 - accuracy: 0.9412 - 97ms/epoch - 3ms/step\n",
      "Epoch 94/200\n",
      "34/34 - 0s - loss: 1.4991 - accuracy: 0.7353 - 90ms/epoch - 3ms/step\n",
      "Epoch 95/200\n",
      "34/34 - 0s - loss: 0.5103 - accuracy: 0.7353 - 96ms/epoch - 3ms/step\n",
      "Epoch 96/200\n",
      "34/34 - 0s - loss: 0.3101 - accuracy: 0.9118 - 94ms/epoch - 3ms/step\n",
      "Epoch 97/200\n",
      "34/34 - 0s - loss: 0.7313 - accuracy: 0.8235 - 84ms/epoch - 2ms/step\n",
      "Epoch 98/200\n",
      "34/34 - 0s - loss: 0.7895 - accuracy: 0.7941 - 97ms/epoch - 3ms/step\n",
      "Epoch 99/200\n",
      "34/34 - 0s - loss: 0.2907 - accuracy: 0.9412 - 80ms/epoch - 2ms/step\n",
      "Epoch 100/200\n",
      "34/34 - 0s - loss: 0.1005 - accuracy: 0.9706 - 71ms/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/200\n",
      "34/34 - 0s - loss: 0.0664 - accuracy: 0.9706 - 73ms/epoch - 2ms/step\n",
      "Epoch 102/200\n",
      "34/34 - 0s - loss: 0.0589 - accuracy: 0.9706 - 84ms/epoch - 2ms/step\n",
      "Epoch 103/200\n",
      "34/34 - 0s - loss: 0.0637 - accuracy: 0.9412 - 77ms/epoch - 2ms/step\n",
      "Epoch 104/200\n",
      "34/34 - 0s - loss: 0.0649 - accuracy: 0.9706 - 84ms/epoch - 2ms/step\n",
      "Epoch 105/200\n",
      "34/34 - 0s - loss: 0.0583 - accuracy: 0.9706 - 62ms/epoch - 2ms/step\n",
      "Epoch 106/200\n",
      "34/34 - 0s - loss: 0.0522 - accuracy: 0.9706 - 72ms/epoch - 2ms/step\n",
      "Epoch 107/200\n",
      "34/34 - 0s - loss: 0.0639 - accuracy: 0.9412 - 79ms/epoch - 2ms/step\n",
      "Epoch 108/200\n",
      "34/34 - 0s - loss: 0.0524 - accuracy: 0.9706 - 100ms/epoch - 3ms/step\n",
      "Epoch 109/200\n",
      "34/34 - 0s - loss: 0.0568 - accuracy: 0.9412 - 92ms/epoch - 3ms/step\n",
      "Epoch 110/200\n",
      "34/34 - 0s - loss: 0.0609 - accuracy: 0.9412 - 87ms/epoch - 3ms/step\n",
      "Epoch 111/200\n",
      "34/34 - 0s - loss: 0.0627 - accuracy: 0.9412 - 73ms/epoch - 2ms/step\n",
      "Epoch 112/200\n",
      "34/34 - 0s - loss: 0.0322 - accuracy: 1.0000 - 72ms/epoch - 2ms/step\n",
      "Epoch 113/200\n",
      "34/34 - 0s - loss: 0.0664 - accuracy: 0.9706 - 84ms/epoch - 2ms/step\n",
      "Epoch 114/200\n",
      "34/34 - 0s - loss: 0.0587 - accuracy: 0.9706 - 71ms/epoch - 2ms/step\n",
      "Epoch 115/200\n",
      "34/34 - 0s - loss: 0.0396 - accuracy: 1.0000 - 70ms/epoch - 2ms/step\n",
      "Epoch 116/200\n",
      "34/34 - 0s - loss: 0.0482 - accuracy: 0.9706 - 84ms/epoch - 2ms/step\n",
      "Epoch 117/200\n",
      "34/34 - 0s - loss: 0.0566 - accuracy: 0.9706 - 74ms/epoch - 2ms/step\n",
      "Epoch 118/200\n",
      "34/34 - 0s - loss: 0.0757 - accuracy: 0.9706 - 75ms/epoch - 2ms/step\n",
      "Epoch 119/200\n",
      "34/34 - 0s - loss: 0.0416 - accuracy: 0.9706 - 79ms/epoch - 2ms/step\n",
      "Epoch 120/200\n",
      "34/34 - 0s - loss: 0.0487 - accuracy: 0.9706 - 72ms/epoch - 2ms/step\n",
      "Epoch 121/200\n",
      "34/34 - 0s - loss: 0.0380 - accuracy: 1.0000 - 75ms/epoch - 2ms/step\n",
      "Epoch 122/200\n",
      "34/34 - 0s - loss: 0.0650 - accuracy: 0.9706 - 75ms/epoch - 2ms/step\n",
      "Epoch 123/200\n",
      "34/34 - 0s - loss: 0.0635 - accuracy: 0.9706 - 74ms/epoch - 2ms/step\n",
      "Epoch 124/200\n",
      "34/34 - 0s - loss: 0.0387 - accuracy: 1.0000 - 83ms/epoch - 2ms/step\n",
      "Epoch 125/200\n",
      "34/34 - 0s - loss: 0.0397 - accuracy: 1.0000 - 70ms/epoch - 2ms/step\n",
      "Epoch 126/200\n",
      "34/34 - 0s - loss: 0.0306 - accuracy: 1.0000 - 71ms/epoch - 2ms/step\n",
      "Epoch 127/200\n",
      "34/34 - 0s - loss: 0.0272 - accuracy: 1.0000 - 75ms/epoch - 2ms/step\n",
      "Epoch 128/200\n",
      "34/34 - 0s - loss: 0.0330 - accuracy: 0.9706 - 77ms/epoch - 2ms/step\n",
      "Epoch 129/200\n",
      "34/34 - 0s - loss: 0.0535 - accuracy: 0.9706 - 71ms/epoch - 2ms/step\n",
      "Epoch 130/200\n",
      "34/34 - 0s - loss: 0.0456 - accuracy: 0.9706 - 77ms/epoch - 2ms/step\n",
      "Epoch 131/200\n",
      "34/34 - 0s - loss: 0.0382 - accuracy: 0.9706 - 81ms/epoch - 2ms/step\n",
      "Epoch 132/200\n",
      "34/34 - 0s - loss: 0.0321 - accuracy: 0.9706 - 70ms/epoch - 2ms/step\n",
      "Epoch 133/200\n",
      "34/34 - 0s - loss: 0.0316 - accuracy: 0.9706 - 79ms/epoch - 2ms/step\n",
      "Epoch 134/200\n",
      "34/34 - 0s - loss: 0.0711 - accuracy: 0.9412 - 82ms/epoch - 2ms/step\n",
      "Epoch 135/200\n",
      "34/34 - 0s - loss: 0.0301 - accuracy: 1.0000 - 73ms/epoch - 2ms/step\n",
      "Epoch 136/200\n",
      "34/34 - 0s - loss: 0.0343 - accuracy: 0.9706 - 76ms/epoch - 2ms/step\n",
      "Epoch 137/200\n",
      "34/34 - 0s - loss: 0.0343 - accuracy: 0.9706 - 83ms/epoch - 2ms/step\n",
      "Epoch 138/200\n",
      "34/34 - 0s - loss: 0.0456 - accuracy: 0.9706 - 86ms/epoch - 3ms/step\n",
      "Epoch 139/200\n",
      "34/34 - 0s - loss: 0.1757 - accuracy: 0.9118 - 79ms/epoch - 2ms/step\n",
      "Epoch 140/200\n",
      "34/34 - 0s - loss: 0.9883 - accuracy: 0.7353 - 74ms/epoch - 2ms/step\n",
      "Epoch 141/200\n",
      "34/34 - 0s - loss: 0.5516 - accuracy: 0.8235 - 76ms/epoch - 2ms/step\n",
      "Epoch 142/200\n",
      "34/34 - 0s - loss: 0.2217 - accuracy: 0.9412 - 72ms/epoch - 2ms/step\n",
      "Epoch 143/200\n",
      "34/34 - 0s - loss: 0.0699 - accuracy: 0.9706 - 78ms/epoch - 2ms/step\n",
      "Epoch 144/200\n",
      "34/34 - 0s - loss: 0.0477 - accuracy: 0.9706 - 74ms/epoch - 2ms/step\n",
      "Epoch 145/200\n",
      "34/34 - 0s - loss: 0.0325 - accuracy: 1.0000 - 82ms/epoch - 2ms/step\n",
      "Epoch 146/200\n",
      "34/34 - 0s - loss: 0.0320 - accuracy: 1.0000 - 74ms/epoch - 2ms/step\n",
      "Epoch 147/200\n",
      "34/34 - 0s - loss: 0.0301 - accuracy: 1.0000 - 79ms/epoch - 2ms/step\n",
      "Epoch 148/200\n",
      "34/34 - 0s - loss: 0.0314 - accuracy: 0.9706 - 75ms/epoch - 2ms/step\n",
      "Epoch 149/200\n",
      "34/34 - 0s - loss: 0.0594 - accuracy: 0.9706 - 78ms/epoch - 2ms/step\n",
      "Epoch 150/200\n",
      "34/34 - 0s - loss: 0.0483 - accuracy: 0.9706 - 86ms/epoch - 3ms/step\n",
      "Epoch 151/200\n",
      "34/34 - 0s - loss: 0.0180 - accuracy: 1.0000 - 75ms/epoch - 2ms/step\n",
      "Epoch 152/200\n",
      "34/34 - 0s - loss: 0.0140 - accuracy: 1.0000 - 76ms/epoch - 2ms/step\n",
      "Epoch 153/200\n",
      "34/34 - 0s - loss: 0.0128 - accuracy: 1.0000 - 77ms/epoch - 2ms/step\n",
      "Epoch 154/200\n",
      "34/34 - 0s - loss: 0.0167 - accuracy: 1.0000 - 79ms/epoch - 2ms/step\n",
      "Epoch 155/200\n",
      "34/34 - 0s - loss: 0.0372 - accuracy: 0.9706 - 86ms/epoch - 3ms/step\n",
      "Epoch 156/200\n",
      "34/34 - 0s - loss: 0.0956 - accuracy: 0.9706 - 77ms/epoch - 2ms/step\n",
      "Epoch 157/200\n",
      "34/34 - 0s - loss: 0.0826 - accuracy: 0.9706 - 82ms/epoch - 2ms/step\n",
      "Epoch 158/200\n",
      "34/34 - 0s - loss: 0.0263 - accuracy: 1.0000 - 76ms/epoch - 2ms/step\n",
      "Epoch 159/200\n",
      "34/34 - 0s - loss: 0.0187 - accuracy: 1.0000 - 76ms/epoch - 2ms/step\n",
      "Epoch 160/200\n",
      "34/34 - 0s - loss: 0.0199 - accuracy: 1.0000 - 79ms/epoch - 2ms/step\n",
      "Epoch 161/200\n",
      "34/34 - 0s - loss: 0.0109 - accuracy: 1.0000 - 75ms/epoch - 2ms/step\n",
      "Epoch 162/200\n",
      "34/34 - 0s - loss: 0.0081 - accuracy: 1.0000 - 83ms/epoch - 2ms/step\n",
      "Epoch 163/200\n",
      "34/34 - 0s - loss: 0.0060 - accuracy: 1.0000 - 73ms/epoch - 2ms/step\n",
      "Epoch 164/200\n",
      "34/34 - 0s - loss: 0.0047 - accuracy: 1.0000 - 72ms/epoch - 2ms/step\n",
      "Epoch 165/200\n",
      "34/34 - 0s - loss: 0.0028 - accuracy: 1.0000 - 68ms/epoch - 2ms/step\n",
      "Epoch 166/200\n",
      "34/34 - 0s - loss: 0.0025 - accuracy: 1.0000 - 86ms/epoch - 3ms/step\n",
      "Epoch 167/200\n",
      "34/34 - 0s - loss: 0.0018 - accuracy: 1.0000 - 68ms/epoch - 2ms/step\n",
      "Epoch 168/200\n",
      "34/34 - 0s - loss: 0.0015 - accuracy: 1.0000 - 76ms/epoch - 2ms/step\n",
      "Epoch 169/200\n",
      "34/34 - 0s - loss: 0.0011 - accuracy: 1.0000 - 80ms/epoch - 2ms/step\n",
      "Epoch 170/200\n",
      "34/34 - 0s - loss: 9.6531e-04 - accuracy: 1.0000 - 72ms/epoch - 2ms/step\n",
      "Epoch 171/200\n",
      "34/34 - 0s - loss: 8.9158e-04 - accuracy: 1.0000 - 72ms/epoch - 2ms/step\n",
      "Epoch 172/200\n",
      "34/34 - 0s - loss: 6.8625e-04 - accuracy: 1.0000 - 85ms/epoch - 2ms/step\n",
      "Epoch 173/200\n",
      "34/34 - 0s - loss: 6.2577e-04 - accuracy: 1.0000 - 73ms/epoch - 2ms/step\n",
      "Epoch 174/200\n",
      "34/34 - 0s - loss: 6.0853e-04 - accuracy: 1.0000 - 75ms/epoch - 2ms/step\n",
      "Epoch 175/200\n",
      "34/34 - 0s - loss: 4.4900e-04 - accuracy: 1.0000 - 85ms/epoch - 3ms/step\n",
      "Epoch 176/200\n",
      "34/34 - 0s - loss: 4.0434e-04 - accuracy: 1.0000 - 75ms/epoch - 2ms/step\n",
      "Epoch 177/200\n",
      "34/34 - 0s - loss: 3.6166e-04 - accuracy: 1.0000 - 80ms/epoch - 2ms/step\n",
      "Epoch 178/200\n",
      "34/34 - 0s - loss: 3.3123e-04 - accuracy: 1.0000 - 73ms/epoch - 2ms/step\n",
      "Epoch 179/200\n",
      "34/34 - 0s - loss: 2.8696e-04 - accuracy: 1.0000 - 74ms/epoch - 2ms/step\n",
      "Epoch 180/200\n",
      "34/34 - 0s - loss: 2.6202e-04 - accuracy: 1.0000 - 80ms/epoch - 2ms/step\n",
      "Epoch 181/200\n",
      "34/34 - 0s - loss: 2.3783e-04 - accuracy: 1.0000 - 74ms/epoch - 2ms/step\n",
      "Epoch 182/200\n",
      "34/34 - 0s - loss: 2.1343e-04 - accuracy: 1.0000 - 80ms/epoch - 2ms/step\n",
      "Epoch 183/200\n",
      "34/34 - 0s - loss: 1.9175e-04 - accuracy: 1.0000 - 77ms/epoch - 2ms/step\n",
      "Epoch 184/200\n",
      "34/34 - 0s - loss: 1.7817e-04 - accuracy: 1.0000 - 78ms/epoch - 2ms/step\n",
      "Epoch 185/200\n",
      "34/34 - 0s - loss: 1.6002e-04 - accuracy: 1.0000 - 79ms/epoch - 2ms/step\n",
      "Epoch 186/200\n",
      "34/34 - 0s - loss: 1.5895e-04 - accuracy: 1.0000 - 73ms/epoch - 2ms/step\n",
      "Epoch 187/200\n",
      "34/34 - 0s - loss: 1.3465e-04 - accuracy: 1.0000 - 75ms/epoch - 2ms/step\n",
      "Epoch 188/200\n",
      "34/34 - 0s - loss: 1.2146e-04 - accuracy: 1.0000 - 69ms/epoch - 2ms/step\n",
      "Epoch 189/200\n",
      "34/34 - 0s - loss: 1.1235e-04 - accuracy: 1.0000 - 80ms/epoch - 2ms/step\n",
      "Epoch 190/200\n",
      "34/34 - 0s - loss: 1.0561e-04 - accuracy: 1.0000 - 74ms/epoch - 2ms/step\n",
      "Epoch 191/200\n",
      "34/34 - 0s - loss: 1.0152e-04 - accuracy: 1.0000 - 70ms/epoch - 2ms/step\n",
      "Epoch 192/200\n",
      "34/34 - 0s - loss: 8.8392e-05 - accuracy: 1.0000 - 86ms/epoch - 3ms/step\n",
      "Epoch 193/200\n",
      "34/34 - 0s - loss: 8.1772e-05 - accuracy: 1.0000 - 68ms/epoch - 2ms/step\n",
      "Epoch 194/200\n",
      "34/34 - 0s - loss: 7.7261e-05 - accuracy: 1.0000 - 68ms/epoch - 2ms/step\n",
      "Epoch 195/200\n",
      "34/34 - 0s - loss: 7.0059e-05 - accuracy: 1.0000 - 83ms/epoch - 2ms/step\n",
      "Epoch 196/200\n",
      "34/34 - 0s - loss: 6.6875e-05 - accuracy: 1.0000 - 73ms/epoch - 2ms/step\n",
      "Epoch 197/200\n",
      "34/34 - 0s - loss: 6.4117e-05 - accuracy: 1.0000 - 75ms/epoch - 2ms/step\n",
      "Epoch 198/200\n",
      "34/34 - 0s - loss: 5.9468e-05 - accuracy: 1.0000 - 80ms/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/200\n",
      "34/34 - 0s - loss: 5.3409e-05 - accuracy: 1.0000 - 74ms/epoch - 2ms/step\n",
      "Epoch 200/200\n",
      "34/34 - 0s - loss: 5.2569e-05 - accuracy: 1.0000 - 72ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x251bdda0670>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=128, activation='relu', input_shape=x_train[0].shape))\n",
    "model.add(Dense(y_train.shape[1],activation='softmax'))\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,optimizer='Adam',metrics=['accuracy'])\n",
    "model.fit(x_train.astype(np.float32),y_train.astype(np.float32),epochs=200,batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b381e405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 4.],\n",
       "        [1., 4.],\n",
       "        [5., 4.],\n",
       "        [5., 4.],\n",
       "        [6., 4.],\n",
       "        [6., 4.],\n",
       "        [5., 2.],\n",
       "        [4., 4.]],\n",
       "\n",
       "       [[1., 4.],\n",
       "        [5., 4.],\n",
       "        [5., 4.],\n",
       "        [6., 4.],\n",
       "        [6., 4.],\n",
       "        [5., 2.],\n",
       "        [4., 4.],\n",
       "        [4., 4.]],\n",
       "\n",
       "       [[5., 4.],\n",
       "        [5., 4.],\n",
       "        [6., 4.],\n",
       "        [6., 4.],\n",
       "        [5., 2.],\n",
       "        [4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.]],\n",
       "\n",
       "       [[5., 4.],\n",
       "        [6., 4.],\n",
       "        [6., 4.],\n",
       "        [5., 2.],\n",
       "        [4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.]],\n",
       "\n",
       "       [[6., 4.],\n",
       "        [6., 4.],\n",
       "        [5., 2.],\n",
       "        [4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.],\n",
       "        [2., 4.]],\n",
       "\n",
       "       [[6., 4.],\n",
       "        [5., 2.],\n",
       "        [4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.],\n",
       "        [2., 4.],\n",
       "        [2., 4.]],\n",
       "\n",
       "       [[5., 2.],\n",
       "        [4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.],\n",
       "        [2., 4.],\n",
       "        [2., 4.],\n",
       "        [1., 2.]],\n",
       "\n",
       "       [[4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.],\n",
       "        [2., 4.],\n",
       "        [2., 4.],\n",
       "        [1., 2.],\n",
       "        [5., 4.]],\n",
       "\n",
       "       [[4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.],\n",
       "        [2., 4.],\n",
       "        [2., 4.],\n",
       "        [1., 2.],\n",
       "        [5., 4.],\n",
       "        [5., 4.]],\n",
       "\n",
       "       [[3., 4.],\n",
       "        [3., 4.],\n",
       "        [2., 4.],\n",
       "        [2., 4.],\n",
       "        [1., 2.],\n",
       "        [5., 4.],\n",
       "        [5., 4.],\n",
       "        [4., 4.]],\n",
       "\n",
       "       [[3., 4.],\n",
       "        [2., 4.],\n",
       "        [2., 4.],\n",
       "        [1., 2.],\n",
       "        [5., 4.],\n",
       "        [5., 4.],\n",
       "        [4., 4.],\n",
       "        [4., 4.]],\n",
       "\n",
       "       [[2., 4.],\n",
       "        [2., 4.],\n",
       "        [1., 2.],\n",
       "        [5., 4.],\n",
       "        [5., 4.],\n",
       "        [4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.]],\n",
       "\n",
       "       [[2., 4.],\n",
       "        [1., 2.],\n",
       "        [5., 4.],\n",
       "        [5., 4.],\n",
       "        [4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.]],\n",
       "\n",
       "       [[1., 2.],\n",
       "        [5., 4.],\n",
       "        [5., 4.],\n",
       "        [4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.],\n",
       "        [2., 2.]],\n",
       "\n",
       "       [[5., 4.],\n",
       "        [5., 4.],\n",
       "        [4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.],\n",
       "        [2., 2.],\n",
       "        [5., 4.]],\n",
       "\n",
       "       [[5., 4.],\n",
       "        [4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.],\n",
       "        [2., 2.],\n",
       "        [5., 4.],\n",
       "        [5., 4.]],\n",
       "\n",
       "       [[4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.],\n",
       "        [2., 2.],\n",
       "        [5., 4.],\n",
       "        [5., 4.],\n",
       "        [4., 4.]],\n",
       "\n",
       "       [[4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.],\n",
       "        [2., 2.],\n",
       "        [5., 4.],\n",
       "        [5., 4.],\n",
       "        [4., 4.],\n",
       "        [4., 4.]],\n",
       "\n",
       "       [[3., 4.],\n",
       "        [3., 4.],\n",
       "        [2., 2.],\n",
       "        [5., 4.],\n",
       "        [5., 4.],\n",
       "        [4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.]],\n",
       "\n",
       "       [[3., 4.],\n",
       "        [2., 2.],\n",
       "        [5., 4.],\n",
       "        [5., 4.],\n",
       "        [4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.]],\n",
       "\n",
       "       [[2., 2.],\n",
       "        [5., 4.],\n",
       "        [5., 4.],\n",
       "        [4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.],\n",
       "        [2., 2.]],\n",
       "\n",
       "       [[5., 4.],\n",
       "        [5., 4.],\n",
       "        [4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.],\n",
       "        [2., 2.],\n",
       "        [1., 4.]],\n",
       "\n",
       "       [[5., 4.],\n",
       "        [4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.],\n",
       "        [2., 2.],\n",
       "        [1., 4.],\n",
       "        [1., 4.]],\n",
       "\n",
       "       [[4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.],\n",
       "        [2., 2.],\n",
       "        [1., 4.],\n",
       "        [1., 4.],\n",
       "        [5., 4.]],\n",
       "\n",
       "       [[4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.],\n",
       "        [2., 2.],\n",
       "        [1., 4.],\n",
       "        [1., 4.],\n",
       "        [5., 4.],\n",
       "        [5., 4.]],\n",
       "\n",
       "       [[3., 4.],\n",
       "        [3., 4.],\n",
       "        [2., 2.],\n",
       "        [1., 4.],\n",
       "        [1., 4.],\n",
       "        [5., 4.],\n",
       "        [5., 4.],\n",
       "        [6., 4.]],\n",
       "\n",
       "       [[3., 4.],\n",
       "        [2., 2.],\n",
       "        [1., 4.],\n",
       "        [1., 4.],\n",
       "        [5., 4.],\n",
       "        [5., 4.],\n",
       "        [6., 4.],\n",
       "        [6., 4.]],\n",
       "\n",
       "       [[2., 2.],\n",
       "        [1., 4.],\n",
       "        [1., 4.],\n",
       "        [5., 4.],\n",
       "        [5., 4.],\n",
       "        [6., 4.],\n",
       "        [6., 4.],\n",
       "        [5., 2.]],\n",
       "\n",
       "       [[1., 4.],\n",
       "        [1., 4.],\n",
       "        [5., 4.],\n",
       "        [5., 4.],\n",
       "        [6., 4.],\n",
       "        [6., 4.],\n",
       "        [5., 2.],\n",
       "        [4., 4.]],\n",
       "\n",
       "       [[1., 4.],\n",
       "        [5., 4.],\n",
       "        [5., 4.],\n",
       "        [6., 4.],\n",
       "        [6., 4.],\n",
       "        [5., 2.],\n",
       "        [4., 4.],\n",
       "        [4., 4.]],\n",
       "\n",
       "       [[5., 4.],\n",
       "        [5., 4.],\n",
       "        [6., 4.],\n",
       "        [6., 4.],\n",
       "        [5., 2.],\n",
       "        [4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.]],\n",
       "\n",
       "       [[5., 4.],\n",
       "        [6., 4.],\n",
       "        [6., 4.],\n",
       "        [5., 2.],\n",
       "        [4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.]],\n",
       "\n",
       "       [[6., 4.],\n",
       "        [6., 4.],\n",
       "        [5., 2.],\n",
       "        [4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.],\n",
       "        [2., 4.]],\n",
       "\n",
       "       [[6., 4.],\n",
       "        [5., 2.],\n",
       "        [4., 4.],\n",
       "        [4., 4.],\n",
       "        [3., 4.],\n",
       "        [3., 4.],\n",
       "        [2., 4.],\n",
       "        [2., 4.]]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.astype(np.float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
